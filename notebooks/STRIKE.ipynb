{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Unable to write current GraphLab Create license to /home/alvas/.graphlab/config. Ensure that this user account has write permission to /home/alvas/.graphlab/config to save the license for offline use.\n",
      "[INFO] This non-commercial license of GraphLab Create is assigned to liling@coli.uni-saarland.de and will expire on October 11, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-4314 - Server binary: /usr/local/lib/python2.7/dist-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1454467908.log\n",
      "[INFO] GraphLab Server Version: 1.8.1\n",
      "[WARNING] Unable to create session in specified location: '/home/alvas/.graphlab/artifacts'. Using: '/var/tmp/graphlab-alvas/4314/tmp_session_0bfd3202-9c71-43dd-bf88-878fce463181'\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from HAMMER import train_xgboost, xgboost_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts_train = gl.SFrame('../sts2016_train.stasis/')\n",
    "sts_test = gl.SFrame('../sts2016_test.stasis/')\n",
    "sts_train = sts_train.dropna(columns=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Boosted trees regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 13597\n",
      "PROGRESS: Number of features          : 3\n",
      "PROGRESS: Number of unpacked features : 3\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 1.033796     | 4.26247            | 2.12918       |\n",
      "PROGRESS: | 2         | 1.041294     | 4.04426            | 1.65681       |\n",
      "PROGRESS: | 3         | 1.048528     | 3.99651            | 1.36361       |\n",
      "PROGRESS: | 4         | 1.055530     | 3.99096            | 1.18997       |\n",
      "PROGRESS: | 5         | 1.063725     | 3.99484            | 1.09257       |\n",
      "PROGRESS: | 6         | 1.073306     | 4.00021            | 1.03826       |\n",
      "PROGRESS: | 7         | 1.080753     | 4.03883            | 1.0079        |\n",
      "PROGRESS: | 8         | 1.088238     | 4.02845            | 0.989975      |\n",
      "PROGRESS: | 9         | 1.095292     | 4.02109            | 0.979727      |\n",
      "PROGRESS: | 10        | 1.101814     | 4.01734            | 0.973249      |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: Boosted trees regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 13597\n",
      "PROGRESS: Number of features          : 5\n",
      "PROGRESS: Number of unpacked features : 5\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 0.034983     | 4.29016            | 2.12701       |\n",
      "PROGRESS: | 2         | 0.044681     | 4.15614            | 1.65009       |\n",
      "PROGRESS: | 3         | 0.053929     | 4.12591            | 1.35135       |\n",
      "PROGRESS: | 4         | 0.064224     | 4.06039            | 1.1742        |\n",
      "PROGRESS: | 5         | 0.074390     | 3.90622            | 1.07174       |\n",
      "PROGRESS: | 6         | 0.085277     | 3.84682            | 1.01482       |\n",
      "PROGRESS: | 7         | 0.095845     | 3.81955            | 0.98082       |\n",
      "PROGRESS: | 8         | 0.105414     | 3.81213            | 0.962032      |\n",
      "PROGRESS: | 9         | 0.115327     | 3.81523            | 0.94871       |\n",
      "PROGRESS: | 10        | 0.124484     | 3.81287            | 0.939375      |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "feat1 = ['prop_harmonic', 'DLS_compose_ppmi', 'DLS_compose_cbow']\n",
    "feat2 = ['glove_cosine', 'prop_harmonic', 'DLS_compose_ppmi', 'DLS_compose_cbow', 'REVAL']\n",
    "m1 = gl.boosted_trees_regression.create(sts_train, target='Score', features=feat1, validation_set=None)\n",
    "m2 = gl.boosted_trees_regression.create(sts_train, target='Score', features=feat2, validation_set=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_valid = sts_train['glove_cosine', 'prop_harmonic', 'DLS_compose_ppmi', 'DLS_compose_cbow', 'REVAL', 'BEER', 'Score'].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-rmse:0.896464\teval-rmse:0.901914\n",
      "[1]\ttrain-rmse:0.880858\teval-rmse:0.886520\n",
      "[2]\ttrain-rmse:0.865902\teval-rmse:0.871817\n",
      "[3]\ttrain-rmse:0.851279\teval-rmse:0.857429\n",
      "[4]\ttrain-rmse:0.836885\teval-rmse:0.843295\n",
      "[5]\ttrain-rmse:0.822560\teval-rmse:0.829205\n",
      "[6]\ttrain-rmse:0.808846\teval-rmse:0.815705\n",
      "[7]\ttrain-rmse:0.795200\teval-rmse:0.802237\n",
      "[8]\ttrain-rmse:0.781826\teval-rmse:0.789128\n",
      "[9]\ttrain-rmse:0.768741\teval-rmse:0.776310\n",
      "[10]\ttrain-rmse:0.755969\teval-rmse:0.763751\n",
      "[11]\ttrain-rmse:0.743701\teval-rmse:0.751778\n",
      "[12]\ttrain-rmse:0.731770\teval-rmse:0.740124\n",
      "[13]\ttrain-rmse:0.719787\teval-rmse:0.728460\n",
      "[14]\ttrain-rmse:0.708106\teval-rmse:0.717065\n",
      "[15]\ttrain-rmse:0.696701\teval-rmse:0.705939\n",
      "[16]\ttrain-rmse:0.685592\teval-rmse:0.695079\n",
      "[17]\ttrain-rmse:0.674940\teval-rmse:0.684842\n",
      "[18]\ttrain-rmse:0.664610\teval-rmse:0.674807\n",
      "[19]\ttrain-rmse:0.654474\teval-rmse:0.665032\n",
      "[20]\ttrain-rmse:0.644584\teval-rmse:0.655439\n",
      "[21]\ttrain-rmse:0.634838\teval-rmse:0.646115\n",
      "[22]\ttrain-rmse:0.625115\teval-rmse:0.636695\n",
      "[23]\ttrain-rmse:0.615904\teval-rmse:0.627821\n",
      "[24]\ttrain-rmse:0.606849\teval-rmse:0.619101\n",
      "[25]\ttrain-rmse:0.598003\teval-rmse:0.610700\n",
      "[26]\ttrain-rmse:0.589189\teval-rmse:0.602235\n",
      "[27]\ttrain-rmse:0.580792\teval-rmse:0.594239\n",
      "[28]\ttrain-rmse:0.572617\teval-rmse:0.586449\n",
      "[29]\ttrain-rmse:0.564625\teval-rmse:0.578867\n",
      "[30]\ttrain-rmse:0.556553\teval-rmse:0.571275\n",
      "[31]\ttrain-rmse:0.548698\teval-rmse:0.563823\n",
      "[32]\ttrain-rmse:0.541279\teval-rmse:0.556821\n",
      "[33]\ttrain-rmse:0.534034\teval-rmse:0.550018\n",
      "[34]\ttrain-rmse:0.526999\teval-rmse:0.543486\n",
      "[35]\ttrain-rmse:0.520114\teval-rmse:0.537082\n",
      "[36]\ttrain-rmse:0.513178\teval-rmse:0.530543\n",
      "[37]\ttrain-rmse:0.506625\teval-rmse:0.524468\n",
      "[38]\ttrain-rmse:0.499991\teval-rmse:0.518322\n",
      "[39]\ttrain-rmse:0.493781\teval-rmse:0.512569\n",
      "[40]\ttrain-rmse:0.487529\teval-rmse:0.506774\n",
      "[41]\ttrain-rmse:0.481646\teval-rmse:0.501349\n",
      "[42]\ttrain-rmse:0.475667\teval-rmse:0.495853\n",
      "[43]\ttrain-rmse:0.470082\teval-rmse:0.490746\n",
      "[44]\ttrain-rmse:0.464649\teval-rmse:0.485794\n",
      "[45]\ttrain-rmse:0.459073\teval-rmse:0.480721\n",
      "[46]\ttrain-rmse:0.453905\teval-rmse:0.475996\n",
      "[47]\ttrain-rmse:0.448835\teval-rmse:0.471454\n",
      "[48]\ttrain-rmse:0.443852\teval-rmse:0.466970\n",
      "[49]\ttrain-rmse:0.439128\teval-rmse:0.462680\n",
      "[50]\ttrain-rmse:0.434508\teval-rmse:0.458565\n",
      "[51]\ttrain-rmse:0.429757\teval-rmse:0.454347\n",
      "[52]\ttrain-rmse:0.425131\teval-rmse:0.450166\n",
      "[53]\ttrain-rmse:0.420807\teval-rmse:0.446469\n",
      "[54]\ttrain-rmse:0.416728\teval-rmse:0.442796\n",
      "[55]\ttrain-rmse:0.412647\teval-rmse:0.439280\n",
      "[56]\ttrain-rmse:0.408454\teval-rmse:0.435599\n",
      "[57]\ttrain-rmse:0.404454\teval-rmse:0.432024\n",
      "[58]\ttrain-rmse:0.400784\teval-rmse:0.428828\n",
      "[59]\ttrain-rmse:0.397164\teval-rmse:0.425689\n",
      "[60]\ttrain-rmse:0.393384\teval-rmse:0.422430\n",
      "[61]\ttrain-rmse:0.389717\teval-rmse:0.419247\n",
      "[62]\ttrain-rmse:0.386373\teval-rmse:0.416400\n",
      "[63]\ttrain-rmse:0.382969\teval-rmse:0.413409\n",
      "[64]\ttrain-rmse:0.379607\teval-rmse:0.410528\n",
      "[65]\ttrain-rmse:0.376282\teval-rmse:0.407770\n",
      "[66]\ttrain-rmse:0.373081\teval-rmse:0.405108\n",
      "[67]\ttrain-rmse:0.370170\teval-rmse:0.402718\n",
      "[68]\ttrain-rmse:0.367111\teval-rmse:0.400182\n",
      "[69]\ttrain-rmse:0.364155\teval-rmse:0.397721\n",
      "[70]\ttrain-rmse:0.361259\teval-rmse:0.395349\n",
      "[71]\ttrain-rmse:0.358633\teval-rmse:0.393233\n",
      "[72]\ttrain-rmse:0.356121\teval-rmse:0.391278\n",
      "[73]\ttrain-rmse:0.353451\teval-rmse:0.389190\n",
      "[74]\ttrain-rmse:0.350892\teval-rmse:0.387132\n",
      "[75]\ttrain-rmse:0.348561\teval-rmse:0.385333\n",
      "[76]\ttrain-rmse:0.346393\teval-rmse:0.383551\n",
      "[77]\ttrain-rmse:0.344045\teval-rmse:0.381641\n",
      "[78]\ttrain-rmse:0.341786\teval-rmse:0.379794\n",
      "[79]\ttrain-rmse:0.339519\teval-rmse:0.378047\n",
      "[80]\ttrain-rmse:0.337298\teval-rmse:0.376335\n",
      "[81]\ttrain-rmse:0.335156\teval-rmse:0.374789\n",
      "[82]\ttrain-rmse:0.333071\teval-rmse:0.373185\n",
      "[83]\ttrain-rmse:0.330978\teval-rmse:0.371692\n",
      "[84]\ttrain-rmse:0.329219\teval-rmse:0.370414\n",
      "[85]\ttrain-rmse:0.327387\teval-rmse:0.369022\n",
      "[86]\ttrain-rmse:0.325578\teval-rmse:0.367699\n",
      "[87]\ttrain-rmse:0.323831\teval-rmse:0.366394\n",
      "[88]\ttrain-rmse:0.322108\teval-rmse:0.365086\n",
      "[89]\ttrain-rmse:0.320537\teval-rmse:0.364017\n",
      "[90]\ttrain-rmse:0.318856\teval-rmse:0.362817\n",
      "[91]\ttrain-rmse:0.317399\teval-rmse:0.361823\n",
      "[92]\ttrain-rmse:0.316029\teval-rmse:0.360810\n",
      "[93]\ttrain-rmse:0.314611\teval-rmse:0.359801\n",
      "[94]\ttrain-rmse:0.313269\teval-rmse:0.358873\n",
      "[95]\ttrain-rmse:0.311909\teval-rmse:0.357971\n",
      "[96]\ttrain-rmse:0.310505\teval-rmse:0.357014\n",
      "[97]\ttrain-rmse:0.309360\teval-rmse:0.356182\n",
      "[98]\ttrain-rmse:0.307955\teval-rmse:0.355301\n",
      "[99]\ttrain-rmse:0.306668\teval-rmse:0.354400\n",
      "[100]\ttrain-rmse:0.305542\teval-rmse:0.353602\n",
      "[101]\ttrain-rmse:0.304464\teval-rmse:0.352888\n",
      "[102]\ttrain-rmse:0.303290\teval-rmse:0.352075\n",
      "[103]\ttrain-rmse:0.302101\teval-rmse:0.351388\n",
      "[104]\ttrain-rmse:0.300895\teval-rmse:0.350622\n",
      "[105]\ttrain-rmse:0.299698\teval-rmse:0.349957\n",
      "[106]\ttrain-rmse:0.298538\teval-rmse:0.349276\n",
      "[107]\ttrain-rmse:0.297505\teval-rmse:0.348574\n",
      "[108]\ttrain-rmse:0.296427\teval-rmse:0.347932\n",
      "[109]\ttrain-rmse:0.295554\teval-rmse:0.347400\n",
      "[110]\ttrain-rmse:0.294682\teval-rmse:0.346944\n",
      "[111]\ttrain-rmse:0.293914\teval-rmse:0.346475\n",
      "[112]\ttrain-rmse:0.293096\teval-rmse:0.345979\n",
      "[113]\ttrain-rmse:0.292174\teval-rmse:0.345487\n",
      "[114]\ttrain-rmse:0.291247\teval-rmse:0.344935\n",
      "[115]\ttrain-rmse:0.290312\teval-rmse:0.344428\n",
      "[116]\ttrain-rmse:0.289353\teval-rmse:0.343924\n",
      "[117]\ttrain-rmse:0.288497\teval-rmse:0.343479\n",
      "[118]\ttrain-rmse:0.287695\teval-rmse:0.343045\n",
      "[119]\ttrain-rmse:0.286958\teval-rmse:0.342670\n",
      "[120]\ttrain-rmse:0.286338\teval-rmse:0.342326\n",
      "[121]\ttrain-rmse:0.285585\teval-rmse:0.341992\n",
      "[122]\ttrain-rmse:0.284795\teval-rmse:0.341585\n",
      "[123]\ttrain-rmse:0.284007\teval-rmse:0.341242\n",
      "[124]\ttrain-rmse:0.283364\teval-rmse:0.340854\n",
      "[125]\ttrain-rmse:0.282746\teval-rmse:0.340627\n",
      "[126]\ttrain-rmse:0.282120\teval-rmse:0.340365\n",
      "[127]\ttrain-rmse:0.281646\teval-rmse:0.340136\n",
      "[128]\ttrain-rmse:0.280951\teval-rmse:0.339820\n",
      "[129]\ttrain-rmse:0.280301\teval-rmse:0.339537\n",
      "[130]\ttrain-rmse:0.279731\teval-rmse:0.339300\n",
      "[131]\ttrain-rmse:0.279144\teval-rmse:0.338968\n",
      "[132]\ttrain-rmse:0.278593\teval-rmse:0.338710\n",
      "[133]\ttrain-rmse:0.277980\teval-rmse:0.338462\n",
      "[134]\ttrain-rmse:0.277404\teval-rmse:0.338233\n",
      "[135]\ttrain-rmse:0.276816\teval-rmse:0.337995\n",
      "[136]\ttrain-rmse:0.276405\teval-rmse:0.337793\n",
      "[137]\ttrain-rmse:0.276001\teval-rmse:0.337620\n",
      "[138]\ttrain-rmse:0.275490\teval-rmse:0.337410\n",
      "[139]\ttrain-rmse:0.274985\teval-rmse:0.337210\n",
      "[140]\ttrain-rmse:0.274534\teval-rmse:0.337014\n",
      "[141]\ttrain-rmse:0.274091\teval-rmse:0.336832\n",
      "[142]\ttrain-rmse:0.273509\teval-rmse:0.336602\n",
      "[143]\ttrain-rmse:0.273011\teval-rmse:0.336407\n",
      "[144]\ttrain-rmse:0.272443\teval-rmse:0.336249\n",
      "[145]\ttrain-rmse:0.272110\teval-rmse:0.336126\n",
      "[146]\ttrain-rmse:0.271801\teval-rmse:0.336013\n",
      "[147]\ttrain-rmse:0.271490\teval-rmse:0.335852\n",
      "[148]\ttrain-rmse:0.271218\teval-rmse:0.335762\n",
      "[149]\ttrain-rmse:0.270727\teval-rmse:0.335569\n",
      "[150]\ttrain-rmse:0.270341\teval-rmse:0.335457\n",
      "[151]\ttrain-rmse:0.269812\teval-rmse:0.335290\n",
      "[152]\ttrain-rmse:0.269370\teval-rmse:0.335158\n",
      "[153]\ttrain-rmse:0.268949\teval-rmse:0.334992\n",
      "[154]\ttrain-rmse:0.268612\teval-rmse:0.334942\n",
      "[155]\ttrain-rmse:0.268161\teval-rmse:0.334809\n",
      "[156]\ttrain-rmse:0.267703\teval-rmse:0.334687\n",
      "[157]\ttrain-rmse:0.267307\teval-rmse:0.334561\n",
      "[158]\ttrain-rmse:0.266977\teval-rmse:0.334473\n",
      "[159]\ttrain-rmse:0.266607\teval-rmse:0.334372\n",
      "[160]\ttrain-rmse:0.266329\teval-rmse:0.334284\n",
      "[161]\ttrain-rmse:0.266018\teval-rmse:0.334178\n",
      "[162]\ttrain-rmse:0.265751\teval-rmse:0.334101\n",
      "[163]\ttrain-rmse:0.265359\teval-rmse:0.334031\n",
      "[164]\ttrain-rmse:0.265029\teval-rmse:0.333983\n",
      "[165]\ttrain-rmse:0.264648\teval-rmse:0.333866\n",
      "[166]\ttrain-rmse:0.264378\teval-rmse:0.333764\n",
      "[167]\ttrain-rmse:0.264063\teval-rmse:0.333704\n",
      "[168]\ttrain-rmse:0.263732\teval-rmse:0.333610\n",
      "[169]\ttrain-rmse:0.263502\teval-rmse:0.333548\n",
      "[170]\ttrain-rmse:0.263110\teval-rmse:0.333473\n",
      "[171]\ttrain-rmse:0.262950\teval-rmse:0.333419\n",
      "[172]\ttrain-rmse:0.262620\teval-rmse:0.333354\n",
      "[173]\ttrain-rmse:0.262325\teval-rmse:0.333280\n",
      "[174]\ttrain-rmse:0.262041\teval-rmse:0.333252\n",
      "[175]\ttrain-rmse:0.261648\teval-rmse:0.333148\n",
      "[176]\ttrain-rmse:0.261388\teval-rmse:0.333067\n",
      "[177]\ttrain-rmse:0.261104\teval-rmse:0.332986\n",
      "[178]\ttrain-rmse:0.260888\teval-rmse:0.332979\n",
      "[179]\ttrain-rmse:0.260638\teval-rmse:0.332924\n",
      "[180]\ttrain-rmse:0.260339\teval-rmse:0.332895\n",
      "[181]\ttrain-rmse:0.259929\teval-rmse:0.332876\n",
      "[182]\ttrain-rmse:0.259611\teval-rmse:0.332808\n",
      "[183]\ttrain-rmse:0.259287\teval-rmse:0.332739\n",
      "[184]\ttrain-rmse:0.259009\teval-rmse:0.332714\n",
      "[185]\ttrain-rmse:0.258834\teval-rmse:0.332681\n",
      "[186]\ttrain-rmse:0.258696\teval-rmse:0.332632\n",
      "[187]\ttrain-rmse:0.258446\teval-rmse:0.332622\n",
      "[188]\ttrain-rmse:0.258256\teval-rmse:0.332605\n",
      "[189]\ttrain-rmse:0.258004\teval-rmse:0.332573\n",
      "[190]\ttrain-rmse:0.257689\teval-rmse:0.332606\n",
      "[191]\ttrain-rmse:0.257452\teval-rmse:0.332556\n",
      "[192]\ttrain-rmse:0.257252\teval-rmse:0.332533\n",
      "[193]\ttrain-rmse:0.256957\teval-rmse:0.332449\n",
      "[194]\ttrain-rmse:0.256779\teval-rmse:0.332424\n",
      "[195]\ttrain-rmse:0.256523\teval-rmse:0.332404\n",
      "[196]\ttrain-rmse:0.256253\teval-rmse:0.332417\n",
      "[197]\ttrain-rmse:0.256076\teval-rmse:0.332423\n",
      "[198]\ttrain-rmse:0.255901\teval-rmse:0.332412\n",
      "[199]\ttrain-rmse:0.255687\teval-rmse:0.332362\n",
      "[200]\ttrain-rmse:0.255463\teval-rmse:0.332359\n",
      "[201]\ttrain-rmse:0.255186\teval-rmse:0.332349\n",
      "[202]\ttrain-rmse:0.255011\teval-rmse:0.332333\n",
      "[203]\ttrain-rmse:0.254745\teval-rmse:0.332343\n",
      "[204]\ttrain-rmse:0.254519\teval-rmse:0.332316\n",
      "[205]\ttrain-rmse:0.254312\teval-rmse:0.332296\n",
      "[206]\ttrain-rmse:0.254133\teval-rmse:0.332262\n",
      "[207]\ttrain-rmse:0.254022\teval-rmse:0.332274\n",
      "[208]\ttrain-rmse:0.253852\teval-rmse:0.332226\n",
      "[209]\ttrain-rmse:0.253639\teval-rmse:0.332217\n",
      "[210]\ttrain-rmse:0.253418\teval-rmse:0.332187\n",
      "[211]\ttrain-rmse:0.253184\teval-rmse:0.332157\n",
      "[212]\ttrain-rmse:0.252973\teval-rmse:0.332147\n",
      "[213]\ttrain-rmse:0.252802\teval-rmse:0.332153\n",
      "[214]\ttrain-rmse:0.252498\teval-rmse:0.332169\n",
      "[215]\ttrain-rmse:0.252313\teval-rmse:0.332157\n",
      "[216]\ttrain-rmse:0.252129\teval-rmse:0.332152\n",
      "[217]\ttrain-rmse:0.251834\teval-rmse:0.332121\n",
      "[218]\ttrain-rmse:0.251737\teval-rmse:0.332091\n",
      "[219]\ttrain-rmse:0.251533\teval-rmse:0.332090\n",
      "[220]\ttrain-rmse:0.251267\teval-rmse:0.332044\n",
      "[221]\ttrain-rmse:0.251049\teval-rmse:0.332050\n",
      "[222]\ttrain-rmse:0.250766\teval-rmse:0.332040\n",
      "[223]\ttrain-rmse:0.250611\teval-rmse:0.332006\n",
      "[224]\ttrain-rmse:0.250362\teval-rmse:0.331981\n",
      "[225]\ttrain-rmse:0.250198\teval-rmse:0.331971\n",
      "[226]\ttrain-rmse:0.249993\teval-rmse:0.332032\n",
      "[227]\ttrain-rmse:0.249829\teval-rmse:0.332033\n",
      "[228]\ttrain-rmse:0.249682\teval-rmse:0.332003\n",
      "[229]\ttrain-rmse:0.249401\teval-rmse:0.331968\n",
      "[230]\ttrain-rmse:0.249272\teval-rmse:0.331944\n",
      "[231]\ttrain-rmse:0.249002\teval-rmse:0.331999\n",
      "[232]\ttrain-rmse:0.248894\teval-rmse:0.331972\n",
      "[233]\ttrain-rmse:0.248719\teval-rmse:0.331939\n",
      "[234]\ttrain-rmse:0.248608\teval-rmse:0.331948\n",
      "[235]\ttrain-rmse:0.248457\teval-rmse:0.331936\n",
      "[236]\ttrain-rmse:0.248305\teval-rmse:0.331930\n",
      "[237]\ttrain-rmse:0.248053\teval-rmse:0.331895\n",
      "[238]\ttrain-rmse:0.247929\teval-rmse:0.331876\n",
      "[239]\ttrain-rmse:0.247761\teval-rmse:0.331878\n",
      "[240]\ttrain-rmse:0.247589\teval-rmse:0.331908\n",
      "[241]\ttrain-rmse:0.247422\teval-rmse:0.331910\n",
      "[242]\ttrain-rmse:0.247265\teval-rmse:0.331922\n",
      "[243]\ttrain-rmse:0.247035\teval-rmse:0.331950\n",
      "[244]\ttrain-rmse:0.246797\teval-rmse:0.331957\n",
      "[245]\ttrain-rmse:0.246634\teval-rmse:0.331927\n",
      "[246]\ttrain-rmse:0.246557\teval-rmse:0.331910\n",
      "[247]\ttrain-rmse:0.246429\teval-rmse:0.331907\n",
      "[248]\ttrain-rmse:0.246275\teval-rmse:0.331929\n",
      "[249]\ttrain-rmse:0.246060\teval-rmse:0.331939\n",
      "[250]\ttrain-rmse:0.245924\teval-rmse:0.331910\n",
      "[251]\ttrain-rmse:0.245758\teval-rmse:0.331907\n",
      "[252]\ttrain-rmse:0.245599\teval-rmse:0.331968\n",
      "[253]\ttrain-rmse:0.245447\teval-rmse:0.331941\n",
      "[254]\ttrain-rmse:0.245261\teval-rmse:0.331966\n",
      "[255]\ttrain-rmse:0.245099\teval-rmse:0.331954\n",
      "[256]\ttrain-rmse:0.244922\teval-rmse:0.331907\n",
      "[257]\ttrain-rmse:0.244706\teval-rmse:0.331900\n",
      "[258]\ttrain-rmse:0.244521\teval-rmse:0.331911\n",
      "[259]\ttrain-rmse:0.244382\teval-rmse:0.331915\n",
      "[260]\ttrain-rmse:0.244271\teval-rmse:0.331921\n",
      "[261]\ttrain-rmse:0.244125\teval-rmse:0.331933\n",
      "[262]\ttrain-rmse:0.244034\teval-rmse:0.331929\n",
      "[263]\ttrain-rmse:0.243893\teval-rmse:0.331935\n",
      "[264]\ttrain-rmse:0.243820\teval-rmse:0.331929\n",
      "[265]\ttrain-rmse:0.243589\teval-rmse:0.331902\n",
      "[266]\ttrain-rmse:0.243463\teval-rmse:0.331918\n",
      "[267]\ttrain-rmse:0.243344\teval-rmse:0.331882\n",
      "[268]\ttrain-rmse:0.243170\teval-rmse:0.331883\n",
      "[269]\ttrain-rmse:0.243118\teval-rmse:0.331868\n",
      "[270]\ttrain-rmse:0.243020\teval-rmse:0.331873\n",
      "[271]\ttrain-rmse:0.242858\teval-rmse:0.331897\n",
      "[272]\ttrain-rmse:0.242733\teval-rmse:0.331897\n",
      "[273]\ttrain-rmse:0.242549\teval-rmse:0.331914\n",
      "[274]\ttrain-rmse:0.242430\teval-rmse:0.331910\n",
      "[275]\ttrain-rmse:0.242172\teval-rmse:0.331911\n",
      "[276]\ttrain-rmse:0.242118\teval-rmse:0.331887\n",
      "[277]\ttrain-rmse:0.241994\teval-rmse:0.331883\n",
      "[278]\ttrain-rmse:0.241930\teval-rmse:0.331863\n",
      "[279]\ttrain-rmse:0.241732\teval-rmse:0.331887\n",
      "[280]\ttrain-rmse:0.241617\teval-rmse:0.331907\n",
      "[281]\ttrain-rmse:0.241388\teval-rmse:0.331932\n",
      "[282]\ttrain-rmse:0.241195\teval-rmse:0.331902\n",
      "[283]\ttrain-rmse:0.241086\teval-rmse:0.331889\n",
      "[284]\ttrain-rmse:0.241029\teval-rmse:0.331895\n",
      "[285]\ttrain-rmse:0.240952\teval-rmse:0.331893\n",
      "[286]\ttrain-rmse:0.240904\teval-rmse:0.331889\n",
      "[287]\ttrain-rmse:0.240840\teval-rmse:0.331891\n",
      "[288]\ttrain-rmse:0.240712\teval-rmse:0.331884\n",
      "[289]\ttrain-rmse:0.240644\teval-rmse:0.331876\n",
      "[290]\ttrain-rmse:0.240613\teval-rmse:0.331872\n",
      "[291]\ttrain-rmse:0.240484\teval-rmse:0.331867\n",
      "[292]\ttrain-rmse:0.240336\teval-rmse:0.331836\n",
      "[293]\ttrain-rmse:0.240218\teval-rmse:0.331858\n",
      "[294]\ttrain-rmse:0.240059\teval-rmse:0.331846\n",
      "[295]\ttrain-rmse:0.239930\teval-rmse:0.331818\n",
      "[296]\ttrain-rmse:0.239803\teval-rmse:0.331812\n",
      "[297]\ttrain-rmse:0.239632\teval-rmse:0.331837\n",
      "[298]\ttrain-rmse:0.239568\teval-rmse:0.331821\n",
      "[299]\ttrain-rmse:0.239455\teval-rmse:0.331808\n",
      "[300]\ttrain-rmse:0.239307\teval-rmse:0.331827\n",
      "[301]\ttrain-rmse:0.239100\teval-rmse:0.331811\n",
      "[302]\ttrain-rmse:0.238958\teval-rmse:0.331840\n",
      "[303]\ttrain-rmse:0.238849\teval-rmse:0.331850\n",
      "[304]\ttrain-rmse:0.238657\teval-rmse:0.331861\n",
      "[305]\ttrain-rmse:0.238501\teval-rmse:0.331870\n",
      "[306]\ttrain-rmse:0.238434\teval-rmse:0.331883\n",
      "[307]\ttrain-rmse:0.238325\teval-rmse:0.331907\n",
      "[308]\ttrain-rmse:0.238226\teval-rmse:0.331908\n",
      "[309]\ttrain-rmse:0.238029\teval-rmse:0.331899\n",
      "[310]\ttrain-rmse:0.237914\teval-rmse:0.331867\n",
      "[311]\ttrain-rmse:0.237673\teval-rmse:0.331853\n",
      "[312]\ttrain-rmse:0.237521\teval-rmse:0.331820\n",
      "[313]\ttrain-rmse:0.237329\teval-rmse:0.331846\n",
      "[314]\ttrain-rmse:0.237202\teval-rmse:0.331860\n",
      "[315]\ttrain-rmse:0.237027\teval-rmse:0.331924\n",
      "[316]\ttrain-rmse:0.236920\teval-rmse:0.331920\n",
      "[317]\ttrain-rmse:0.236769\teval-rmse:0.331927\n",
      "[318]\ttrain-rmse:0.236608\teval-rmse:0.331907\n",
      "[319]\ttrain-rmse:0.236436\teval-rmse:0.331914\n",
      "[320]\ttrain-rmse:0.236301\teval-rmse:0.331894\n",
      "[321]\ttrain-rmse:0.236125\teval-rmse:0.331842\n",
      "[322]\ttrain-rmse:0.236020\teval-rmse:0.331848\n",
      "[323]\ttrain-rmse:0.235906\teval-rmse:0.331817\n",
      "[324]\ttrain-rmse:0.235822\teval-rmse:0.331810\n",
      "[325]\ttrain-rmse:0.235704\teval-rmse:0.331824\n",
      "[326]\ttrain-rmse:0.235663\teval-rmse:0.331813\n",
      "[327]\ttrain-rmse:0.235572\teval-rmse:0.331796\n",
      "[328]\ttrain-rmse:0.235486\teval-rmse:0.331797\n",
      "[329]\ttrain-rmse:0.235401\teval-rmse:0.331827\n",
      "[330]\ttrain-rmse:0.235387\teval-rmse:0.331825\n",
      "[331]\ttrain-rmse:0.235268\teval-rmse:0.331830\n",
      "[332]\ttrain-rmse:0.235174\teval-rmse:0.331855\n",
      "[333]\ttrain-rmse:0.235060\teval-rmse:0.331856\n",
      "[334]\ttrain-rmse:0.234920\teval-rmse:0.331846\n",
      "[335]\ttrain-rmse:0.234715\teval-rmse:0.331865\n",
      "[336]\ttrain-rmse:0.234584\teval-rmse:0.331845\n",
      "[337]\ttrain-rmse:0.234531\teval-rmse:0.331840\n",
      "[338]\ttrain-rmse:0.234387\teval-rmse:0.331842\n",
      "[339]\ttrain-rmse:0.234310\teval-rmse:0.331834\n",
      "[340]\ttrain-rmse:0.234207\teval-rmse:0.331800\n",
      "[341]\ttrain-rmse:0.234088\teval-rmse:0.331817\n",
      "[342]\ttrain-rmse:0.234020\teval-rmse:0.331792\n",
      "[343]\ttrain-rmse:0.233892\teval-rmse:0.331806\n",
      "[344]\ttrain-rmse:0.233756\teval-rmse:0.331803\n",
      "[345]\ttrain-rmse:0.233730\teval-rmse:0.331804\n",
      "[346]\ttrain-rmse:0.233616\teval-rmse:0.331795\n",
      "[347]\ttrain-rmse:0.233555\teval-rmse:0.331793\n",
      "[348]\ttrain-rmse:0.233496\teval-rmse:0.331795\n",
      "[349]\ttrain-rmse:0.233409\teval-rmse:0.331799\n",
      "[350]\ttrain-rmse:0.233311\teval-rmse:0.331775\n",
      "[351]\ttrain-rmse:0.233191\teval-rmse:0.331795\n",
      "[352]\ttrain-rmse:0.233036\teval-rmse:0.331803\n",
      "[353]\ttrain-rmse:0.232896\teval-rmse:0.331845\n",
      "[354]\ttrain-rmse:0.232838\teval-rmse:0.331838\n",
      "[355]\ttrain-rmse:0.232721\teval-rmse:0.331852\n",
      "[356]\ttrain-rmse:0.232575\teval-rmse:0.331853\n",
      "[357]\ttrain-rmse:0.232472\teval-rmse:0.331857\n",
      "[358]\ttrain-rmse:0.232329\teval-rmse:0.331843\n",
      "[359]\ttrain-rmse:0.232202\teval-rmse:0.331825\n",
      "[360]\ttrain-rmse:0.232021\teval-rmse:0.331784\n",
      "[361]\ttrain-rmse:0.231913\teval-rmse:0.331780\n",
      "[362]\ttrain-rmse:0.231779\teval-rmse:0.331778\n",
      "[363]\ttrain-rmse:0.231631\teval-rmse:0.331781\n",
      "[364]\ttrain-rmse:0.231538\teval-rmse:0.331798\n",
      "[365]\ttrain-rmse:0.231481\teval-rmse:0.331792\n",
      "[366]\ttrain-rmse:0.231389\teval-rmse:0.331783\n",
      "[367]\ttrain-rmse:0.231342\teval-rmse:0.331784\n",
      "[368]\ttrain-rmse:0.231202\teval-rmse:0.331793\n",
      "[369]\ttrain-rmse:0.231071\teval-rmse:0.331789\n",
      "[370]\ttrain-rmse:0.230913\teval-rmse:0.331785\n",
      "[371]\ttrain-rmse:0.230789\teval-rmse:0.331777\n",
      "[372]\ttrain-rmse:0.230680\teval-rmse:0.331782\n",
      "[373]\ttrain-rmse:0.230569\teval-rmse:0.331745\n",
      "[374]\ttrain-rmse:0.230342\teval-rmse:0.331753\n",
      "[375]\ttrain-rmse:0.230283\teval-rmse:0.331747\n",
      "[376]\ttrain-rmse:0.230146\teval-rmse:0.331764\n",
      "[377]\ttrain-rmse:0.230055\teval-rmse:0.331765\n",
      "[378]\ttrain-rmse:0.229941\teval-rmse:0.331764\n",
      "[379]\ttrain-rmse:0.229903\teval-rmse:0.331758\n",
      "[380]\ttrain-rmse:0.229791\teval-rmse:0.331754\n",
      "[381]\ttrain-rmse:0.229683\teval-rmse:0.331746\n",
      "[382]\ttrain-rmse:0.229518\teval-rmse:0.331740\n",
      "[383]\ttrain-rmse:0.229486\teval-rmse:0.331733\n",
      "[384]\ttrain-rmse:0.229278\teval-rmse:0.331730\n",
      "[385]\ttrain-rmse:0.229101\teval-rmse:0.331720\n",
      "[386]\ttrain-rmse:0.229035\teval-rmse:0.331719\n",
      "[387]\ttrain-rmse:0.228980\teval-rmse:0.331721\n",
      "[388]\ttrain-rmse:0.228898\teval-rmse:0.331710\n",
      "[389]\ttrain-rmse:0.228844\teval-rmse:0.331696\n",
      "[390]\ttrain-rmse:0.228766\teval-rmse:0.331701\n",
      "[391]\ttrain-rmse:0.228531\teval-rmse:0.331699\n",
      "[392]\ttrain-rmse:0.228428\teval-rmse:0.331702\n",
      "[393]\ttrain-rmse:0.228337\teval-rmse:0.331707\n",
      "[394]\ttrain-rmse:0.228285\teval-rmse:0.331710\n",
      "[395]\ttrain-rmse:0.228128\teval-rmse:0.331667\n",
      "[396]\ttrain-rmse:0.228053\teval-rmse:0.331674\n",
      "[397]\ttrain-rmse:0.227967\teval-rmse:0.331680\n",
      "[398]\ttrain-rmse:0.227885\teval-rmse:0.331694\n",
      "[399]\ttrain-rmse:0.227769\teval-rmse:0.331685\n",
      "[400]\ttrain-rmse:0.227706\teval-rmse:0.331682\n",
      "[401]\ttrain-rmse:0.227464\teval-rmse:0.331655\n",
      "[402]\ttrain-rmse:0.227355\teval-rmse:0.331636\n",
      "[403]\ttrain-rmse:0.227247\teval-rmse:0.331655\n",
      "[404]\ttrain-rmse:0.227217\teval-rmse:0.331648\n",
      "[405]\ttrain-rmse:0.227119\teval-rmse:0.331632\n",
      "[406]\ttrain-rmse:0.227094\teval-rmse:0.331627\n",
      "[407]\ttrain-rmse:0.227002\teval-rmse:0.331622\n",
      "[408]\ttrain-rmse:0.226775\teval-rmse:0.331625\n",
      "[409]\ttrain-rmse:0.226723\teval-rmse:0.331626\n",
      "[410]\ttrain-rmse:0.226668\teval-rmse:0.331633\n",
      "[411]\ttrain-rmse:0.226571\teval-rmse:0.331629\n",
      "[412]\ttrain-rmse:0.226434\teval-rmse:0.331645\n",
      "[413]\ttrain-rmse:0.226334\teval-rmse:0.331670\n",
      "[414]\ttrain-rmse:0.226214\teval-rmse:0.331664\n",
      "[415]\ttrain-rmse:0.226143\teval-rmse:0.331636\n",
      "[416]\ttrain-rmse:0.225939\teval-rmse:0.331653\n",
      "[417]\ttrain-rmse:0.225846\teval-rmse:0.331658\n",
      "[418]\ttrain-rmse:0.225736\teval-rmse:0.331646\n",
      "[419]\ttrain-rmse:0.225607\teval-rmse:0.331639\n",
      "[420]\ttrain-rmse:0.225457\teval-rmse:0.331652\n",
      "[421]\ttrain-rmse:0.225359\teval-rmse:0.331655\n",
      "[422]\ttrain-rmse:0.225279\teval-rmse:0.331662\n",
      "[423]\ttrain-rmse:0.225171\teval-rmse:0.331679\n",
      "[424]\ttrain-rmse:0.225121\teval-rmse:0.331675\n",
      "[425]\ttrain-rmse:0.225038\teval-rmse:0.331674\n",
      "[426]\ttrain-rmse:0.224994\teval-rmse:0.331655\n",
      "[427]\ttrain-rmse:0.224913\teval-rmse:0.331665\n",
      "[428]\ttrain-rmse:0.224852\teval-rmse:0.331660\n",
      "[429]\ttrain-rmse:0.224759\teval-rmse:0.331675\n",
      "[430]\ttrain-rmse:0.224678\teval-rmse:0.331660\n",
      "[431]\ttrain-rmse:0.224544\teval-rmse:0.331679\n",
      "[432]\ttrain-rmse:0.224509\teval-rmse:0.331673\n",
      "[433]\ttrain-rmse:0.224440\teval-rmse:0.331694\n",
      "[434]\ttrain-rmse:0.224297\teval-rmse:0.331679\n",
      "[435]\ttrain-rmse:0.224233\teval-rmse:0.331691\n",
      "[436]\ttrain-rmse:0.224168\teval-rmse:0.331701\n",
      "[437]\ttrain-rmse:0.224134\teval-rmse:0.331700\n",
      "[438]\ttrain-rmse:0.224044\teval-rmse:0.331717\n",
      "[439]\ttrain-rmse:0.223960\teval-rmse:0.331684\n",
      "[440]\ttrain-rmse:0.223790\teval-rmse:0.331678\n",
      "[441]\ttrain-rmse:0.223678\teval-rmse:0.331676\n",
      "[442]\ttrain-rmse:0.223556\teval-rmse:0.331705\n",
      "[443]\ttrain-rmse:0.223449\teval-rmse:0.331708\n",
      "[444]\ttrain-rmse:0.223315\teval-rmse:0.331738\n",
      "[445]\ttrain-rmse:0.223194\teval-rmse:0.331753\n",
      "[446]\ttrain-rmse:0.223057\teval-rmse:0.331731\n",
      "[447]\ttrain-rmse:0.222982\teval-rmse:0.331734\n",
      "[448]\ttrain-rmse:0.222916\teval-rmse:0.331742\n",
      "[449]\ttrain-rmse:0.222872\teval-rmse:0.331733\n",
      "[450]\ttrain-rmse:0.222785\teval-rmse:0.331760\n",
      "[451]\ttrain-rmse:0.222698\teval-rmse:0.331758\n",
      "[452]\ttrain-rmse:0.222588\teval-rmse:0.331765\n",
      "[453]\ttrain-rmse:0.222542\teval-rmse:0.331756\n",
      "[454]\ttrain-rmse:0.222476\teval-rmse:0.331747\n",
      "[455]\ttrain-rmse:0.222395\teval-rmse:0.331763\n",
      "[456]\ttrain-rmse:0.222268\teval-rmse:0.331776\n",
      "[457]\ttrain-rmse:0.222093\teval-rmse:0.331798\n",
      "[458]\ttrain-rmse:0.221974\teval-rmse:0.331797\n",
      "[459]\ttrain-rmse:0.221882\teval-rmse:0.331786\n",
      "[460]\ttrain-rmse:0.221783\teval-rmse:0.331764\n",
      "[461]\ttrain-rmse:0.221658\teval-rmse:0.331762\n",
      "[462]\ttrain-rmse:0.221533\teval-rmse:0.331787\n",
      "[463]\ttrain-rmse:0.221454\teval-rmse:0.331767\n",
      "[464]\ttrain-rmse:0.221372\teval-rmse:0.331764\n",
      "[465]\ttrain-rmse:0.221276\teval-rmse:0.331788\n",
      "[466]\ttrain-rmse:0.221198\teval-rmse:0.331768\n",
      "[467]\ttrain-rmse:0.221121\teval-rmse:0.331790\n",
      "[468]\ttrain-rmse:0.221002\teval-rmse:0.331811\n",
      "[469]\ttrain-rmse:0.220941\teval-rmse:0.331809\n",
      "[470]\ttrain-rmse:0.220699\teval-rmse:0.331832\n",
      "[471]\ttrain-rmse:0.220636\teval-rmse:0.331845\n",
      "[472]\ttrain-rmse:0.220483\teval-rmse:0.331856\n",
      "[473]\ttrain-rmse:0.220389\teval-rmse:0.331849\n",
      "[474]\ttrain-rmse:0.220286\teval-rmse:0.331841\n",
      "[475]\ttrain-rmse:0.220172\teval-rmse:0.331847\n",
      "[476]\ttrain-rmse:0.220081\teval-rmse:0.331839\n",
      "[477]\ttrain-rmse:0.220043\teval-rmse:0.331843\n",
      "[478]\ttrain-rmse:0.219973\teval-rmse:0.331830\n",
      "[479]\ttrain-rmse:0.219916\teval-rmse:0.331847\n",
      "[480]\ttrain-rmse:0.219780\teval-rmse:0.331890\n",
      "[481]\ttrain-rmse:0.219698\teval-rmse:0.331895\n",
      "[482]\ttrain-rmse:0.219571\teval-rmse:0.331913\n",
      "[483]\ttrain-rmse:0.219477\teval-rmse:0.331918\n",
      "[484]\ttrain-rmse:0.219296\teval-rmse:0.331915\n",
      "[485]\ttrain-rmse:0.219199\teval-rmse:0.331920\n",
      "[486]\ttrain-rmse:0.219018\teval-rmse:0.331898\n",
      "[487]\ttrain-rmse:0.218893\teval-rmse:0.331903\n",
      "[488]\ttrain-rmse:0.218831\teval-rmse:0.331922\n",
      "[489]\ttrain-rmse:0.218739\teval-rmse:0.331928\n",
      "[490]\ttrain-rmse:0.218585\teval-rmse:0.331909\n",
      "[491]\ttrain-rmse:0.218477\teval-rmse:0.331892\n",
      "[492]\ttrain-rmse:0.218374\teval-rmse:0.331895\n",
      "[493]\ttrain-rmse:0.218336\teval-rmse:0.331886\n",
      "[494]\ttrain-rmse:0.218248\teval-rmse:0.331913\n",
      "[495]\ttrain-rmse:0.218232\teval-rmse:0.331915\n",
      "[496]\ttrain-rmse:0.218173\teval-rmse:0.331895\n",
      "[497]\ttrain-rmse:0.218111\teval-rmse:0.331882\n",
      "[498]\ttrain-rmse:0.218017\teval-rmse:0.331869\n",
      "[499]\ttrain-rmse:0.217908\teval-rmse:0.331851\n",
      "[500]\ttrain-rmse:0.217801\teval-rmse:0.331854\n",
      "[501]\ttrain-rmse:0.217697\teval-rmse:0.331872\n",
      "[502]\ttrain-rmse:0.217547\teval-rmse:0.331865\n",
      "[503]\ttrain-rmse:0.217386\teval-rmse:0.331838\n",
      "[504]\ttrain-rmse:0.217293\teval-rmse:0.331818\n",
      "[505]\ttrain-rmse:0.217166\teval-rmse:0.331784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "RMSE: 1.017281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[506]\ttrain-rmse:0.217146\teval-rmse:0.331781\n",
      "[507]\ttrain-rmse:0.217066\teval-rmse:0.331802\n",
      "Stopping. Best iteration:\n",
      "[407]\ttrain-rmse:0.227002\teval-rmse:0.331622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = train_xgboost(train_valid, feat2, num_boost_round=5000, eta=0.02, max_depth=8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = xgboost_predict(gbm, sts_test[feat2].to_dataframe(), feat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "\n",
    "def output_to_file(team_name, run_name, target):\n",
    "    test_dir = '../sts2016-english-v1.1/'\n",
    "    filenames = [test_dir+i for i in os.listdir(test_dir) if i.endswith('ascii')]\n",
    "    for infile in filenames:\n",
    "        domain = infile.rpartition('.')[0].rpartition('.')[2]\n",
    "        outfile = 'STS2016.OUTPUT.'+team_name+'.'+run_name+'.'+domain+'.txt'\n",
    "        with io.open(infile, 'r') as fin, io.open(outfile, 'w') as fout:\n",
    "            domain_data = sts_test.filter_by(domain, column_name='Domain')\n",
    "            for line, row in zip(fin, domain_data):\n",
    "                #line = line.split('\\t')\n",
    "                #s1, s2 = line[0], line[1]\n",
    "                fout.write(unicode(row[target])+'\\n')\n",
    "\n",
    "sts_test.add_column(gl.SArray(m1.predict(sts_test)), name='pred_m1')\n",
    "sts_test.add_column(gl.SArray(m2.predict(sts_test)), name='pred_m2')                \n",
    "sts_test.add_column(gl.SArray(predictions), name='pred_xgboost')\n",
    "output_to_file('wolvesaar', 'DLS-replica', 'pred_m1')\n",
    "output_to_file('wolvesaar', 'lotsa-embeddings', 'pred_m2')\n",
    "output_to_file('wolvesaar', 'xgboost', 'pred_xgboost')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
