{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Unable to write current GraphLab Create license to /home/alvas/.graphlab/config. Ensure that this user account has write permission to /home/alvas/.graphlab/config to save the license for offline use.\n",
      "[INFO] This non-commercial license of GraphLab Create is assigned to liling@coli.uni-saarland.de and will expire on October 11, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-30374 - Server binary: /usr/local/lib/python2.7/dist-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1454464092.log\n",
      "[INFO] GraphLab Server Version: 1.8.1\n",
      "[WARNING] Unable to create session in specified location: '/home/alvas/.graphlab/artifacts'. Using: '/var/tmp/graphlab-alvas/30374/tmp_session_2eb4e4b3-04bd-4751-9974-c79bb5133d3b'\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from HAMMER import train_xgboost, xgboost_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts_train = gl.SFrame('../sts2016_train.stasis/')\n",
    "sts_test = gl.SFrame('../sts2016_test.stasis/')\n",
    "sts_train = sts_train.dropna(columns=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Boosted trees regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 13597\n",
      "PROGRESS: Number of features          : 3\n",
      "PROGRESS: Number of unpacked features : 3\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 1.029581     | 4.26247            | 2.12918       |\n",
      "PROGRESS: | 2         | 1.036718     | 4.04426            | 1.65681       |\n",
      "PROGRESS: | 3         | 1.045100     | 3.99651            | 1.36361       |\n",
      "PROGRESS: | 4         | 1.052687     | 3.99096            | 1.18997       |\n",
      "PROGRESS: | 5         | 1.060311     | 3.99484            | 1.09257       |\n",
      "PROGRESS: | 6         | 1.068820     | 4.00021            | 1.03826       |\n",
      "PROGRESS: | 7         | 1.077671     | 4.03883            | 1.0079        |\n",
      "PROGRESS: | 8         | 1.085742     | 4.02845            | 0.989975      |\n",
      "PROGRESS: | 9         | 1.093457     | 4.02109            | 0.979727      |\n",
      "PROGRESS: | 10        | 1.101288     | 4.01734            | 0.973249      |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: Boosted trees regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 13597\n",
      "PROGRESS: Number of features          : 6\n",
      "PROGRESS: Number of unpacked features : 6\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 0.035218     | 4.37462            | 2.12404       |\n",
      "PROGRESS: | 2         | 0.048811     | 4.08551            | 1.64508       |\n",
      "PROGRESS: | 3         | 0.062438     | 4.01973            | 1.34288       |\n",
      "PROGRESS: | 4         | 0.076568     | 3.84888            | 1.16198       |\n",
      "PROGRESS: | 5         | 0.090301     | 3.86811            | 1.05746       |\n",
      "PROGRESS: | 6         | 0.102755     | 3.76926            | 0.998426      |\n",
      "PROGRESS: | 7         | 0.116356     | 3.76357            | 0.963456      |\n",
      "PROGRESS: | 8         | 0.135766     | 3.75353            | 0.943434      |\n",
      "PROGRESS: | 9         | 0.154125     | 3.72277            | 0.930914      |\n",
      "PROGRESS: | 10        | 0.171733     | 3.71403            | 0.91875       |\n",
      "PROGRESS: +-----------+--------------+--------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "feat1 = ['prop_harmonic', 'DLS_compose_ppmi', 'DLS_compose_cbow']\n",
    "feat2 = ['glove_cosine', 'prop_harmonic', 'DLS_compose_ppmi', 'DLS_compose_cbow', 'REVAL', 'BEER']\n",
    "m1 = gl.boosted_trees_regression.create(sts_train, target='Score', features=feat1, validation_set=None)\n",
    "m2 = gl.boosted_trees_regression.create(sts_train, target='Score', features=feat2, validation_set=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_valid = sts_train['glove_cosine', 'prop_harmonic', 'DLS_compose_ppmi', 'DLS_compose_cbow', 'REVAL', 'BEER', 'Score'].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-rmse:0.896152\teval-rmse:0.901518\n",
      "[1]\ttrain-rmse:0.880577\teval-rmse:0.886048\n",
      "[2]\ttrain-rmse:0.865539\teval-rmse:0.871229\n",
      "[3]\ttrain-rmse:0.850636\teval-rmse:0.856462\n",
      "[4]\ttrain-rmse:0.836006\teval-rmse:0.842031\n",
      "[5]\ttrain-rmse:0.821759\teval-rmse:0.828008\n",
      "[6]\ttrain-rmse:0.808060\teval-rmse:0.814521\n",
      "[7]\ttrain-rmse:0.794441\teval-rmse:0.801071\n",
      "[8]\ttrain-rmse:0.781371\teval-rmse:0.788285\n",
      "[9]\ttrain-rmse:0.768570\teval-rmse:0.775681\n",
      "[10]\ttrain-rmse:0.756081\teval-rmse:0.763567\n",
      "[11]\ttrain-rmse:0.743806\teval-rmse:0.751607\n",
      "[12]\ttrain-rmse:0.731799\teval-rmse:0.739883\n",
      "[13]\ttrain-rmse:0.719854\teval-rmse:0.728134\n",
      "[14]\ttrain-rmse:0.708187\teval-rmse:0.716678\n",
      "[15]\ttrain-rmse:0.696814\teval-rmse:0.705497\n",
      "[16]\ttrain-rmse:0.685873\teval-rmse:0.694909\n",
      "[17]\ttrain-rmse:0.675261\teval-rmse:0.684585\n",
      "[18]\ttrain-rmse:0.664602\teval-rmse:0.674208\n",
      "[19]\ttrain-rmse:0.654332\teval-rmse:0.664331\n",
      "[20]\ttrain-rmse:0.644129\teval-rmse:0.654446\n",
      "[21]\ttrain-rmse:0.634107\teval-rmse:0.644818\n",
      "[22]\ttrain-rmse:0.624429\teval-rmse:0.635511\n",
      "[23]\ttrain-rmse:0.614855\teval-rmse:0.626279\n",
      "[24]\ttrain-rmse:0.605771\teval-rmse:0.617652\n",
      "[25]\ttrain-rmse:0.596690\teval-rmse:0.608927\n",
      "[26]\ttrain-rmse:0.588058\teval-rmse:0.600803\n",
      "[27]\ttrain-rmse:0.579632\teval-rmse:0.592750\n",
      "[28]\ttrain-rmse:0.571236\teval-rmse:0.584652\n",
      "[29]\ttrain-rmse:0.563123\teval-rmse:0.577005\n",
      "[30]\ttrain-rmse:0.555237\teval-rmse:0.569527\n",
      "[31]\ttrain-rmse:0.547293\teval-rmse:0.561992\n",
      "[32]\ttrain-rmse:0.539774\teval-rmse:0.554851\n",
      "[33]\ttrain-rmse:0.532492\teval-rmse:0.548009\n",
      "[34]\ttrain-rmse:0.525370\teval-rmse:0.541416\n",
      "[35]\ttrain-rmse:0.518254\teval-rmse:0.534689\n",
      "[36]\ttrain-rmse:0.511478\teval-rmse:0.528417\n",
      "[37]\ttrain-rmse:0.504940\teval-rmse:0.522351\n",
      "[38]\ttrain-rmse:0.498360\teval-rmse:0.516177\n",
      "[39]\ttrain-rmse:0.491897\teval-rmse:0.510231\n",
      "[40]\ttrain-rmse:0.485741\teval-rmse:0.504560\n",
      "[41]\ttrain-rmse:0.479546\teval-rmse:0.498830\n",
      "[42]\ttrain-rmse:0.473762\teval-rmse:0.493517\n",
      "[43]\ttrain-rmse:0.468151\teval-rmse:0.488341\n",
      "[44]\ttrain-rmse:0.462618\teval-rmse:0.483331\n",
      "[45]\ttrain-rmse:0.457149\teval-rmse:0.478233\n",
      "[46]\ttrain-rmse:0.452089\teval-rmse:0.473552\n",
      "[47]\ttrain-rmse:0.446834\teval-rmse:0.468774\n",
      "[48]\ttrain-rmse:0.441884\teval-rmse:0.464251\n",
      "[49]\ttrain-rmse:0.436917\teval-rmse:0.459763\n",
      "[50]\ttrain-rmse:0.431997\teval-rmse:0.455301\n",
      "[51]\ttrain-rmse:0.427388\teval-rmse:0.451210\n",
      "[52]\ttrain-rmse:0.422760\teval-rmse:0.447057\n",
      "[53]\ttrain-rmse:0.418378\teval-rmse:0.443185\n",
      "[54]\ttrain-rmse:0.414150\teval-rmse:0.439466\n",
      "[55]\ttrain-rmse:0.410085\teval-rmse:0.435832\n",
      "[56]\ttrain-rmse:0.405909\teval-rmse:0.432076\n",
      "[57]\ttrain-rmse:0.401723\teval-rmse:0.428438\n",
      "[58]\ttrain-rmse:0.397734\teval-rmse:0.424918\n",
      "[59]\ttrain-rmse:0.393888\teval-rmse:0.421524\n",
      "[60]\ttrain-rmse:0.390272\teval-rmse:0.418538\n",
      "[61]\ttrain-rmse:0.386827\teval-rmse:0.415620\n",
      "[62]\ttrain-rmse:0.383371\teval-rmse:0.412681\n",
      "[63]\ttrain-rmse:0.380048\teval-rmse:0.409849\n",
      "[64]\ttrain-rmse:0.376617\teval-rmse:0.406937\n",
      "[65]\ttrain-rmse:0.373313\teval-rmse:0.404183\n",
      "[66]\ttrain-rmse:0.370064\teval-rmse:0.401564\n",
      "[67]\ttrain-rmse:0.366961\teval-rmse:0.398896\n",
      "[68]\ttrain-rmse:0.363916\teval-rmse:0.396337\n",
      "[69]\ttrain-rmse:0.361190\teval-rmse:0.394017\n",
      "[70]\ttrain-rmse:0.358306\teval-rmse:0.391645\n",
      "[71]\ttrain-rmse:0.355698\teval-rmse:0.389463\n",
      "[72]\ttrain-rmse:0.353068\teval-rmse:0.387383\n",
      "[73]\ttrain-rmse:0.350304\teval-rmse:0.385165\n",
      "[74]\ttrain-rmse:0.347734\teval-rmse:0.383084\n",
      "[75]\ttrain-rmse:0.345388\teval-rmse:0.381177\n",
      "[76]\ttrain-rmse:0.343071\teval-rmse:0.379336\n",
      "[77]\ttrain-rmse:0.340665\teval-rmse:0.377432\n",
      "[78]\ttrain-rmse:0.338530\teval-rmse:0.375749\n",
      "[79]\ttrain-rmse:0.336313\teval-rmse:0.373988\n",
      "[80]\ttrain-rmse:0.334088\teval-rmse:0.372246\n",
      "[81]\ttrain-rmse:0.332087\teval-rmse:0.370656\n",
      "[82]\ttrain-rmse:0.329948\teval-rmse:0.369065\n",
      "[83]\ttrain-rmse:0.327915\teval-rmse:0.367532\n",
      "[84]\ttrain-rmse:0.326054\teval-rmse:0.366135\n",
      "[85]\ttrain-rmse:0.324107\teval-rmse:0.364708\n",
      "[86]\ttrain-rmse:0.322387\teval-rmse:0.363389\n",
      "[87]\ttrain-rmse:0.320552\teval-rmse:0.362025\n",
      "[88]\ttrain-rmse:0.318942\teval-rmse:0.360909\n",
      "[89]\ttrain-rmse:0.317331\teval-rmse:0.359764\n",
      "[90]\ttrain-rmse:0.315787\teval-rmse:0.358697\n",
      "[91]\ttrain-rmse:0.314156\teval-rmse:0.357502\n",
      "[92]\ttrain-rmse:0.312606\teval-rmse:0.356356\n",
      "[93]\ttrain-rmse:0.311185\teval-rmse:0.355301\n",
      "[94]\ttrain-rmse:0.309839\teval-rmse:0.354283\n",
      "[95]\ttrain-rmse:0.308408\teval-rmse:0.353241\n",
      "[96]\ttrain-rmse:0.307091\teval-rmse:0.352306\n",
      "[97]\ttrain-rmse:0.305673\teval-rmse:0.351359\n",
      "[98]\ttrain-rmse:0.304237\teval-rmse:0.350452\n",
      "[99]\ttrain-rmse:0.302871\teval-rmse:0.349594\n",
      "[100]\ttrain-rmse:0.301751\teval-rmse:0.348811\n",
      "[101]\ttrain-rmse:0.300526\teval-rmse:0.348012\n",
      "[102]\ttrain-rmse:0.299450\teval-rmse:0.347316\n",
      "[103]\ttrain-rmse:0.298384\teval-rmse:0.346619\n",
      "[104]\ttrain-rmse:0.297290\teval-rmse:0.345914\n",
      "[105]\ttrain-rmse:0.296044\teval-rmse:0.345240\n",
      "[106]\ttrain-rmse:0.294830\teval-rmse:0.344449\n",
      "[107]\ttrain-rmse:0.293845\teval-rmse:0.343765\n",
      "[108]\ttrain-rmse:0.292850\teval-rmse:0.343197\n",
      "[109]\ttrain-rmse:0.291786\teval-rmse:0.342628\n",
      "[110]\ttrain-rmse:0.290832\teval-rmse:0.341980\n",
      "[111]\ttrain-rmse:0.289845\teval-rmse:0.341380\n",
      "[112]\ttrain-rmse:0.289041\teval-rmse:0.340881\n",
      "[113]\ttrain-rmse:0.288094\teval-rmse:0.340399\n",
      "[114]\ttrain-rmse:0.287094\teval-rmse:0.339846\n",
      "[115]\ttrain-rmse:0.286239\teval-rmse:0.339320\n",
      "[116]\ttrain-rmse:0.285485\teval-rmse:0.338871\n",
      "[117]\ttrain-rmse:0.284758\teval-rmse:0.338470\n",
      "[118]\ttrain-rmse:0.283960\teval-rmse:0.337997\n",
      "[119]\ttrain-rmse:0.283232\teval-rmse:0.337601\n",
      "[120]\ttrain-rmse:0.282553\teval-rmse:0.337238\n",
      "[121]\ttrain-rmse:0.281742\teval-rmse:0.336782\n",
      "[122]\ttrain-rmse:0.280930\teval-rmse:0.336371\n",
      "[123]\ttrain-rmse:0.280130\teval-rmse:0.335992\n",
      "[124]\ttrain-rmse:0.279332\teval-rmse:0.335594\n",
      "[125]\ttrain-rmse:0.278772\teval-rmse:0.335309\n",
      "[126]\ttrain-rmse:0.277956\teval-rmse:0.334969\n",
      "[127]\ttrain-rmse:0.277225\teval-rmse:0.334692\n",
      "[128]\ttrain-rmse:0.276570\teval-rmse:0.334426\n",
      "[129]\ttrain-rmse:0.275930\teval-rmse:0.334083\n",
      "[130]\ttrain-rmse:0.275227\teval-rmse:0.333734\n",
      "[131]\ttrain-rmse:0.274496\teval-rmse:0.333400\n",
      "[132]\ttrain-rmse:0.273877\teval-rmse:0.333092\n",
      "[133]\ttrain-rmse:0.273322\teval-rmse:0.332830\n",
      "[134]\ttrain-rmse:0.272749\teval-rmse:0.332580\n",
      "[135]\ttrain-rmse:0.272153\teval-rmse:0.332355\n",
      "[136]\ttrain-rmse:0.271631\teval-rmse:0.332132\n",
      "[137]\ttrain-rmse:0.270990\teval-rmse:0.331818\n",
      "[138]\ttrain-rmse:0.270564\teval-rmse:0.331622\n",
      "[139]\ttrain-rmse:0.269887\teval-rmse:0.331348\n",
      "[140]\ttrain-rmse:0.269467\teval-rmse:0.331149\n",
      "[141]\ttrain-rmse:0.269023\teval-rmse:0.330970\n",
      "[142]\ttrain-rmse:0.268595\teval-rmse:0.330820\n",
      "[143]\ttrain-rmse:0.268162\teval-rmse:0.330652\n",
      "[144]\ttrain-rmse:0.267653\teval-rmse:0.330501\n",
      "[145]\ttrain-rmse:0.267192\teval-rmse:0.330332\n",
      "[146]\ttrain-rmse:0.266768\teval-rmse:0.330179\n",
      "[147]\ttrain-rmse:0.266357\teval-rmse:0.330027\n",
      "[148]\ttrain-rmse:0.266010\teval-rmse:0.329869\n",
      "[149]\ttrain-rmse:0.265458\teval-rmse:0.329679\n",
      "[150]\ttrain-rmse:0.265070\teval-rmse:0.329550\n",
      "[151]\ttrain-rmse:0.264655\teval-rmse:0.329427\n",
      "[152]\ttrain-rmse:0.264268\teval-rmse:0.329322\n",
      "[153]\ttrain-rmse:0.263828\teval-rmse:0.329198\n",
      "[154]\ttrain-rmse:0.263298\teval-rmse:0.329094\n",
      "[155]\ttrain-rmse:0.262873\teval-rmse:0.329010\n",
      "[156]\ttrain-rmse:0.262590\teval-rmse:0.328897\n",
      "[157]\ttrain-rmse:0.262242\teval-rmse:0.328783\n",
      "[158]\ttrain-rmse:0.261909\teval-rmse:0.328701\n",
      "[159]\ttrain-rmse:0.261429\teval-rmse:0.328524\n",
      "[160]\ttrain-rmse:0.261021\teval-rmse:0.328449\n",
      "[161]\ttrain-rmse:0.260700\teval-rmse:0.328376\n",
      "[162]\ttrain-rmse:0.260422\teval-rmse:0.328293\n",
      "[163]\ttrain-rmse:0.260160\teval-rmse:0.328180\n",
      "[164]\ttrain-rmse:0.259777\teval-rmse:0.328103\n",
      "[165]\ttrain-rmse:0.259397\teval-rmse:0.328013\n",
      "[166]\ttrain-rmse:0.259038\teval-rmse:0.327926\n",
      "[167]\ttrain-rmse:0.258615\teval-rmse:0.327845\n",
      "[168]\ttrain-rmse:0.258383\teval-rmse:0.327795\n",
      "[169]\ttrain-rmse:0.258026\teval-rmse:0.327740\n",
      "[170]\ttrain-rmse:0.257645\teval-rmse:0.327713\n",
      "[171]\ttrain-rmse:0.257282\teval-rmse:0.327598\n",
      "[172]\ttrain-rmse:0.256977\teval-rmse:0.327514\n",
      "[173]\ttrain-rmse:0.256665\teval-rmse:0.327474\n",
      "[174]\ttrain-rmse:0.256285\teval-rmse:0.327389\n",
      "[175]\ttrain-rmse:0.255923\teval-rmse:0.327360\n",
      "[176]\ttrain-rmse:0.255673\teval-rmse:0.327361\n",
      "[177]\ttrain-rmse:0.255450\teval-rmse:0.327335\n",
      "[178]\ttrain-rmse:0.255153\teval-rmse:0.327262\n",
      "[179]\ttrain-rmse:0.254776\teval-rmse:0.327198\n",
      "[180]\ttrain-rmse:0.254564\teval-rmse:0.327168\n",
      "[181]\ttrain-rmse:0.254275\teval-rmse:0.327064\n",
      "[182]\ttrain-rmse:0.254058\teval-rmse:0.326975\n",
      "[183]\ttrain-rmse:0.253850\teval-rmse:0.326973\n",
      "[184]\ttrain-rmse:0.253667\teval-rmse:0.326933\n",
      "[185]\ttrain-rmse:0.253362\teval-rmse:0.326884\n",
      "[186]\ttrain-rmse:0.253043\teval-rmse:0.326823\n",
      "[187]\ttrain-rmse:0.252654\teval-rmse:0.326754\n",
      "[188]\ttrain-rmse:0.252497\teval-rmse:0.326709\n",
      "[189]\ttrain-rmse:0.252261\teval-rmse:0.326609\n",
      "[190]\ttrain-rmse:0.252003\teval-rmse:0.326531\n",
      "[191]\ttrain-rmse:0.251812\teval-rmse:0.326511\n",
      "[192]\ttrain-rmse:0.251622\teval-rmse:0.326468\n",
      "[193]\ttrain-rmse:0.251305\teval-rmse:0.326445\n",
      "[194]\ttrain-rmse:0.251091\teval-rmse:0.326396\n",
      "[195]\ttrain-rmse:0.250947\teval-rmse:0.326394\n",
      "[196]\ttrain-rmse:0.250709\teval-rmse:0.326381\n",
      "[197]\ttrain-rmse:0.250411\teval-rmse:0.326341\n",
      "[198]\ttrain-rmse:0.250151\teval-rmse:0.326293\n",
      "[199]\ttrain-rmse:0.249965\teval-rmse:0.326313\n",
      "[200]\ttrain-rmse:0.249728\teval-rmse:0.326309\n",
      "[201]\ttrain-rmse:0.249583\teval-rmse:0.326279\n",
      "[202]\ttrain-rmse:0.249367\teval-rmse:0.326270\n",
      "[203]\ttrain-rmse:0.249023\teval-rmse:0.326263\n",
      "[204]\ttrain-rmse:0.248776\teval-rmse:0.326260\n",
      "[205]\ttrain-rmse:0.248564\teval-rmse:0.326245\n",
      "[206]\ttrain-rmse:0.248381\teval-rmse:0.326217\n",
      "[207]\ttrain-rmse:0.248243\teval-rmse:0.326215\n",
      "[208]\ttrain-rmse:0.247884\teval-rmse:0.326175\n",
      "[209]\ttrain-rmse:0.247681\teval-rmse:0.326133\n",
      "[210]\ttrain-rmse:0.247507\teval-rmse:0.326110\n",
      "[211]\ttrain-rmse:0.247290\teval-rmse:0.326145\n",
      "[212]\ttrain-rmse:0.247004\teval-rmse:0.326130\n",
      "[213]\ttrain-rmse:0.246918\teval-rmse:0.326109\n",
      "[214]\ttrain-rmse:0.246618\teval-rmse:0.326045\n",
      "[215]\ttrain-rmse:0.246508\teval-rmse:0.326040\n",
      "[216]\ttrain-rmse:0.246253\teval-rmse:0.326025\n",
      "[217]\ttrain-rmse:0.245923\teval-rmse:0.326038\n",
      "[218]\ttrain-rmse:0.245719\teval-rmse:0.326047\n",
      "[219]\ttrain-rmse:0.245513\teval-rmse:0.326030\n",
      "[220]\ttrain-rmse:0.245360\teval-rmse:0.325993\n",
      "[221]\ttrain-rmse:0.245194\teval-rmse:0.325957\n",
      "[222]\ttrain-rmse:0.244994\teval-rmse:0.325929\n",
      "[223]\ttrain-rmse:0.244822\teval-rmse:0.325893\n",
      "[224]\ttrain-rmse:0.244581\teval-rmse:0.325909\n",
      "[225]\ttrain-rmse:0.244398\teval-rmse:0.325925\n",
      "[226]\ttrain-rmse:0.244189\teval-rmse:0.325900\n",
      "[227]\ttrain-rmse:0.244011\teval-rmse:0.325898\n",
      "[228]\ttrain-rmse:0.243740\teval-rmse:0.325850\n",
      "[229]\ttrain-rmse:0.243520\teval-rmse:0.325862\n",
      "[230]\ttrain-rmse:0.243356\teval-rmse:0.325856\n",
      "[231]\ttrain-rmse:0.243100\teval-rmse:0.325835\n",
      "[232]\ttrain-rmse:0.242948\teval-rmse:0.325839\n",
      "[233]\ttrain-rmse:0.242676\teval-rmse:0.325802\n",
      "[234]\ttrain-rmse:0.242506\teval-rmse:0.325796\n",
      "[235]\ttrain-rmse:0.242236\teval-rmse:0.325780\n",
      "[236]\ttrain-rmse:0.241998\teval-rmse:0.325790\n",
      "[237]\ttrain-rmse:0.241710\teval-rmse:0.325755\n",
      "[238]\ttrain-rmse:0.241464\teval-rmse:0.325690\n",
      "[239]\ttrain-rmse:0.241286\teval-rmse:0.325666\n",
      "[240]\ttrain-rmse:0.241138\teval-rmse:0.325653\n",
      "[241]\ttrain-rmse:0.240842\teval-rmse:0.325626\n",
      "[242]\ttrain-rmse:0.240614\teval-rmse:0.325631\n",
      "[243]\ttrain-rmse:0.240536\teval-rmse:0.325623\n",
      "[244]\ttrain-rmse:0.240297\teval-rmse:0.325629\n",
      "[245]\ttrain-rmse:0.240035\teval-rmse:0.325602\n",
      "[246]\ttrain-rmse:0.239826\teval-rmse:0.325590\n",
      "[247]\ttrain-rmse:0.239660\teval-rmse:0.325573\n",
      "[248]\ttrain-rmse:0.239520\teval-rmse:0.325559\n",
      "[249]\ttrain-rmse:0.239288\teval-rmse:0.325560\n",
      "[250]\ttrain-rmse:0.239135\teval-rmse:0.325579\n",
      "[251]\ttrain-rmse:0.239047\teval-rmse:0.325564\n",
      "[252]\ttrain-rmse:0.238873\teval-rmse:0.325554\n",
      "[253]\ttrain-rmse:0.238765\teval-rmse:0.325535\n",
      "[254]\ttrain-rmse:0.238544\teval-rmse:0.325536\n",
      "[255]\ttrain-rmse:0.238341\teval-rmse:0.325518\n",
      "[256]\ttrain-rmse:0.238152\teval-rmse:0.325464\n",
      "[257]\ttrain-rmse:0.238049\teval-rmse:0.325417\n",
      "[258]\ttrain-rmse:0.237803\teval-rmse:0.325353\n",
      "[259]\ttrain-rmse:0.237667\teval-rmse:0.325345\n",
      "[260]\ttrain-rmse:0.237381\teval-rmse:0.325361\n",
      "[261]\ttrain-rmse:0.237260\teval-rmse:0.325349\n",
      "[262]\ttrain-rmse:0.237157\teval-rmse:0.325353\n",
      "[263]\ttrain-rmse:0.236979\teval-rmse:0.325348\n",
      "[264]\ttrain-rmse:0.236833\teval-rmse:0.325350\n",
      "[265]\ttrain-rmse:0.236722\teval-rmse:0.325344\n",
      "[266]\ttrain-rmse:0.236564\teval-rmse:0.325313\n",
      "[267]\ttrain-rmse:0.236429\teval-rmse:0.325303\n",
      "[268]\ttrain-rmse:0.236283\teval-rmse:0.325311\n",
      "[269]\ttrain-rmse:0.236151\teval-rmse:0.325289\n",
      "[270]\ttrain-rmse:0.236020\teval-rmse:0.325237\n",
      "[271]\ttrain-rmse:0.235844\teval-rmse:0.325240\n",
      "[272]\ttrain-rmse:0.235711\teval-rmse:0.325236\n",
      "[273]\ttrain-rmse:0.235518\teval-rmse:0.325223\n",
      "[274]\ttrain-rmse:0.235372\teval-rmse:0.325195\n",
      "[275]\ttrain-rmse:0.235168\teval-rmse:0.325168\n",
      "[276]\ttrain-rmse:0.235070\teval-rmse:0.325139\n",
      "[277]\ttrain-rmse:0.234918\teval-rmse:0.325146\n",
      "[278]\ttrain-rmse:0.234653\teval-rmse:0.325156\n",
      "[279]\ttrain-rmse:0.234399\teval-rmse:0.325148\n",
      "[280]\ttrain-rmse:0.234255\teval-rmse:0.325136\n",
      "[281]\ttrain-rmse:0.234034\teval-rmse:0.325124\n",
      "[282]\ttrain-rmse:0.233896\teval-rmse:0.325138\n",
      "[283]\ttrain-rmse:0.233787\teval-rmse:0.325130\n",
      "[284]\ttrain-rmse:0.233579\teval-rmse:0.325116\n",
      "[285]\ttrain-rmse:0.233459\teval-rmse:0.325107\n",
      "[286]\ttrain-rmse:0.233301\teval-rmse:0.325116\n",
      "[287]\ttrain-rmse:0.233145\teval-rmse:0.325134\n",
      "[288]\ttrain-rmse:0.233041\teval-rmse:0.325145\n",
      "[289]\ttrain-rmse:0.232786\teval-rmse:0.325093\n",
      "[290]\ttrain-rmse:0.232702\teval-rmse:0.325102\n",
      "[291]\ttrain-rmse:0.232610\teval-rmse:0.325101\n",
      "[292]\ttrain-rmse:0.232407\teval-rmse:0.325115\n",
      "[293]\ttrain-rmse:0.232169\teval-rmse:0.325117\n",
      "[294]\ttrain-rmse:0.231951\teval-rmse:0.325049\n",
      "[295]\ttrain-rmse:0.231790\teval-rmse:0.325079\n",
      "[296]\ttrain-rmse:0.231674\teval-rmse:0.325102\n",
      "[297]\ttrain-rmse:0.231518\teval-rmse:0.325120\n",
      "[298]\ttrain-rmse:0.231387\teval-rmse:0.325126\n",
      "[299]\ttrain-rmse:0.231272\teval-rmse:0.325140\n",
      "[300]\ttrain-rmse:0.231136\teval-rmse:0.325155\n",
      "[301]\ttrain-rmse:0.230972\teval-rmse:0.325150\n",
      "[302]\ttrain-rmse:0.230895\teval-rmse:0.325147\n",
      "[303]\ttrain-rmse:0.230788\teval-rmse:0.325137\n",
      "[304]\ttrain-rmse:0.230642\teval-rmse:0.325150\n",
      "[305]\ttrain-rmse:0.230454\teval-rmse:0.325151\n",
      "[306]\ttrain-rmse:0.230268\teval-rmse:0.325138\n",
      "[307]\ttrain-rmse:0.230077\teval-rmse:0.325083\n",
      "[308]\ttrain-rmse:0.229941\teval-rmse:0.325076\n",
      "[309]\ttrain-rmse:0.229795\teval-rmse:0.325094\n",
      "[310]\ttrain-rmse:0.229615\teval-rmse:0.325101\n",
      "[311]\ttrain-rmse:0.229439\teval-rmse:0.325109\n",
      "[312]\ttrain-rmse:0.229338\teval-rmse:0.325110\n",
      "[313]\ttrain-rmse:0.229147\teval-rmse:0.325124\n",
      "[314]\ttrain-rmse:0.229002\teval-rmse:0.325102\n",
      "[315]\ttrain-rmse:0.228882\teval-rmse:0.325081\n",
      "[316]\ttrain-rmse:0.228707\teval-rmse:0.325091\n",
      "[317]\ttrain-rmse:0.228468\teval-rmse:0.325057\n",
      "[318]\ttrain-rmse:0.228336\teval-rmse:0.325106\n",
      "[319]\ttrain-rmse:0.228098\teval-rmse:0.325050\n",
      "[320]\ttrain-rmse:0.227960\teval-rmse:0.325094\n",
      "[321]\ttrain-rmse:0.227812\teval-rmse:0.325076\n",
      "[322]\ttrain-rmse:0.227626\teval-rmse:0.325105\n",
      "[323]\ttrain-rmse:0.227430\teval-rmse:0.325102\n",
      "[324]\ttrain-rmse:0.227228\teval-rmse:0.325089\n",
      "[325]\ttrain-rmse:0.227057\teval-rmse:0.325095\n",
      "[326]\ttrain-rmse:0.226909\teval-rmse:0.325096\n",
      "[327]\ttrain-rmse:0.226802\teval-rmse:0.325085\n",
      "[328]\ttrain-rmse:0.226663\teval-rmse:0.325055\n",
      "[329]\ttrain-rmse:0.226513\teval-rmse:0.325076\n",
      "[330]\ttrain-rmse:0.226441\teval-rmse:0.325062\n",
      "[331]\ttrain-rmse:0.226294\teval-rmse:0.325079\n",
      "[332]\ttrain-rmse:0.226223\teval-rmse:0.325085\n",
      "[333]\ttrain-rmse:0.226050\teval-rmse:0.325084\n",
      "[334]\ttrain-rmse:0.225944\teval-rmse:0.325071\n",
      "[335]\ttrain-rmse:0.225716\teval-rmse:0.325050\n",
      "[336]\ttrain-rmse:0.225572\teval-rmse:0.325063\n",
      "[337]\ttrain-rmse:0.225444\teval-rmse:0.325080\n",
      "[338]\ttrain-rmse:0.225268\teval-rmse:0.325090\n",
      "[339]\ttrain-rmse:0.225160\teval-rmse:0.325081\n",
      "[340]\ttrain-rmse:0.224962\teval-rmse:0.325083\n",
      "[341]\ttrain-rmse:0.224813\teval-rmse:0.325069\n",
      "[342]\ttrain-rmse:0.224731\teval-rmse:0.325059\n",
      "[343]\ttrain-rmse:0.224706\teval-rmse:0.325051\n",
      "[344]\ttrain-rmse:0.224571\teval-rmse:0.325038\n",
      "[345]\ttrain-rmse:0.224421\teval-rmse:0.325019\n",
      "[346]\ttrain-rmse:0.224313\teval-rmse:0.325015\n",
      "[347]\ttrain-rmse:0.224161\teval-rmse:0.325033\n",
      "[348]\ttrain-rmse:0.224112\teval-rmse:0.325046\n",
      "[349]\ttrain-rmse:0.223991\teval-rmse:0.325047\n",
      "[350]\ttrain-rmse:0.223899\teval-rmse:0.325062\n",
      "[351]\ttrain-rmse:0.223795\teval-rmse:0.325079\n",
      "[352]\ttrain-rmse:0.223532\teval-rmse:0.325101\n",
      "[353]\ttrain-rmse:0.223353\teval-rmse:0.325096\n",
      "[354]\ttrain-rmse:0.223214\teval-rmse:0.325089\n",
      "[355]\ttrain-rmse:0.223089\teval-rmse:0.325068\n",
      "[356]\ttrain-rmse:0.222992\teval-rmse:0.325070\n",
      "[357]\ttrain-rmse:0.222909\teval-rmse:0.325071\n",
      "[358]\ttrain-rmse:0.222769\teval-rmse:0.325080\n",
      "[359]\ttrain-rmse:0.222660\teval-rmse:0.325074\n",
      "[360]\ttrain-rmse:0.222572\teval-rmse:0.325080\n",
      "[361]\ttrain-rmse:0.222512\teval-rmse:0.325080\n",
      "[362]\ttrain-rmse:0.222437\teval-rmse:0.325070\n",
      "[363]\ttrain-rmse:0.222333\teval-rmse:0.325077\n",
      "[364]\ttrain-rmse:0.222249\teval-rmse:0.325076\n",
      "[365]\ttrain-rmse:0.222103\teval-rmse:0.325067\n",
      "[366]\ttrain-rmse:0.221923\teval-rmse:0.325068\n",
      "[367]\ttrain-rmse:0.221757\teval-rmse:0.325081\n",
      "[368]\ttrain-rmse:0.221669\teval-rmse:0.325091\n",
      "[369]\ttrain-rmse:0.221554\teval-rmse:0.325083\n",
      "[370]\ttrain-rmse:0.221425\teval-rmse:0.325085\n",
      "[371]\ttrain-rmse:0.221235\teval-rmse:0.325077\n",
      "[372]\ttrain-rmse:0.221194\teval-rmse:0.325079\n",
      "[373]\ttrain-rmse:0.221112\teval-rmse:0.325052\n",
      "[374]\ttrain-rmse:0.221009\teval-rmse:0.325051\n",
      "[375]\ttrain-rmse:0.220829\teval-rmse:0.325026\n",
      "[376]\ttrain-rmse:0.220679\teval-rmse:0.325024\n",
      "[377]\ttrain-rmse:0.220627\teval-rmse:0.325026\n",
      "[378]\ttrain-rmse:0.220540\teval-rmse:0.325001\n",
      "[379]\ttrain-rmse:0.220439\teval-rmse:0.324999\n",
      "[380]\ttrain-rmse:0.220345\teval-rmse:0.324996\n",
      "[381]\ttrain-rmse:0.220168\teval-rmse:0.324977\n",
      "[382]\ttrain-rmse:0.220100\teval-rmse:0.324967\n",
      "[383]\ttrain-rmse:0.219994\teval-rmse:0.324955\n",
      "[384]\ttrain-rmse:0.219862\teval-rmse:0.324934\n",
      "[385]\ttrain-rmse:0.219817\teval-rmse:0.324928\n",
      "[386]\ttrain-rmse:0.219670\teval-rmse:0.324944\n",
      "[387]\ttrain-rmse:0.219443\teval-rmse:0.324937\n",
      "[388]\ttrain-rmse:0.219311\teval-rmse:0.324914\n",
      "[389]\ttrain-rmse:0.219221\teval-rmse:0.324940\n",
      "[390]\ttrain-rmse:0.219151\teval-rmse:0.324960\n",
      "[391]\ttrain-rmse:0.218993\teval-rmse:0.324958\n",
      "[392]\ttrain-rmse:0.218933\teval-rmse:0.324940\n",
      "[393]\ttrain-rmse:0.218748\teval-rmse:0.324941\n",
      "[394]\ttrain-rmse:0.218682\teval-rmse:0.324938\n",
      "[395]\ttrain-rmse:0.218546\teval-rmse:0.324929\n",
      "[396]\ttrain-rmse:0.218421\teval-rmse:0.324946\n",
      "[397]\ttrain-rmse:0.218277\teval-rmse:0.324908\n",
      "[398]\ttrain-rmse:0.218164\teval-rmse:0.324940\n",
      "[399]\ttrain-rmse:0.218040\teval-rmse:0.324928\n",
      "[400]\ttrain-rmse:0.217937\teval-rmse:0.324927\n",
      "[401]\ttrain-rmse:0.217797\teval-rmse:0.324904\n",
      "[402]\ttrain-rmse:0.217686\teval-rmse:0.324882\n",
      "[403]\ttrain-rmse:0.217444\teval-rmse:0.324865\n",
      "[404]\ttrain-rmse:0.217340\teval-rmse:0.324868\n",
      "[405]\ttrain-rmse:0.217183\teval-rmse:0.324859\n",
      "[406]\ttrain-rmse:0.216993\teval-rmse:0.324905\n",
      "[407]\ttrain-rmse:0.216903\teval-rmse:0.324887\n",
      "[408]\ttrain-rmse:0.216751\teval-rmse:0.324867\n",
      "[409]\ttrain-rmse:0.216666\teval-rmse:0.324872\n",
      "[410]\ttrain-rmse:0.216604\teval-rmse:0.324867\n",
      "[411]\ttrain-rmse:0.216448\teval-rmse:0.324858\n",
      "[412]\ttrain-rmse:0.216385\teval-rmse:0.324854\n",
      "[413]\ttrain-rmse:0.216295\teval-rmse:0.324871\n",
      "[414]\ttrain-rmse:0.216217\teval-rmse:0.324859\n",
      "[415]\ttrain-rmse:0.216052\teval-rmse:0.324893\n",
      "[416]\ttrain-rmse:0.216020\teval-rmse:0.324907\n",
      "[417]\ttrain-rmse:0.215891\teval-rmse:0.324907\n",
      "[418]\ttrain-rmse:0.215754\teval-rmse:0.324910\n",
      "[419]\ttrain-rmse:0.215603\teval-rmse:0.324884\n",
      "[420]\ttrain-rmse:0.215533\teval-rmse:0.324899\n",
      "[421]\ttrain-rmse:0.215504\teval-rmse:0.324893\n",
      "[422]\ttrain-rmse:0.215419\teval-rmse:0.324893\n",
      "[423]\ttrain-rmse:0.215300\teval-rmse:0.324897\n",
      "[424]\ttrain-rmse:0.215132\teval-rmse:0.324900\n",
      "[425]\ttrain-rmse:0.214934\teval-rmse:0.324886\n",
      "[426]\ttrain-rmse:0.214806\teval-rmse:0.324896\n",
      "[427]\ttrain-rmse:0.214687\teval-rmse:0.324874\n",
      "[428]\ttrain-rmse:0.214641\teval-rmse:0.324876\n",
      "[429]\ttrain-rmse:0.214580\teval-rmse:0.324880\n",
      "[430]\ttrain-rmse:0.214472\teval-rmse:0.324854\n",
      "[431]\ttrain-rmse:0.214383\teval-rmse:0.324855\n",
      "[432]\ttrain-rmse:0.214302\teval-rmse:0.324842\n",
      "[433]\ttrain-rmse:0.214244\teval-rmse:0.324836\n",
      "[434]\ttrain-rmse:0.214151\teval-rmse:0.324854\n",
      "[435]\ttrain-rmse:0.214087\teval-rmse:0.324835\n",
      "[436]\ttrain-rmse:0.213977\teval-rmse:0.324810\n",
      "[437]\ttrain-rmse:0.213893\teval-rmse:0.324850\n",
      "[438]\ttrain-rmse:0.213746\teval-rmse:0.324883\n",
      "[439]\ttrain-rmse:0.213547\teval-rmse:0.324877\n",
      "[440]\ttrain-rmse:0.213462\teval-rmse:0.324879\n",
      "[441]\ttrain-rmse:0.213396\teval-rmse:0.324896\n",
      "[442]\ttrain-rmse:0.213277\teval-rmse:0.324881\n",
      "[443]\ttrain-rmse:0.213116\teval-rmse:0.324889\n",
      "[444]\ttrain-rmse:0.213011\teval-rmse:0.324900\n",
      "[445]\ttrain-rmse:0.212910\teval-rmse:0.324901\n",
      "[446]\ttrain-rmse:0.212858\teval-rmse:0.324905\n",
      "[447]\ttrain-rmse:0.212730\teval-rmse:0.324890\n",
      "[448]\ttrain-rmse:0.212628\teval-rmse:0.324889\n",
      "[449]\ttrain-rmse:0.212522\teval-rmse:0.324898\n",
      "[450]\ttrain-rmse:0.212467\teval-rmse:0.324901\n",
      "[451]\ttrain-rmse:0.212315\teval-rmse:0.324904\n",
      "[452]\ttrain-rmse:0.212172\teval-rmse:0.324889\n",
      "[453]\ttrain-rmse:0.212027\teval-rmse:0.324896\n",
      "[454]\ttrain-rmse:0.211932\teval-rmse:0.324883\n",
      "[455]\ttrain-rmse:0.211865\teval-rmse:0.324862\n",
      "[456]\ttrain-rmse:0.211766\teval-rmse:0.324870\n",
      "[457]\ttrain-rmse:0.211710\teval-rmse:0.324852\n",
      "[458]\ttrain-rmse:0.211649\teval-rmse:0.324835\n",
      "[459]\ttrain-rmse:0.211601\teval-rmse:0.324823\n",
      "[460]\ttrain-rmse:0.211485\teval-rmse:0.324807\n",
      "[461]\ttrain-rmse:0.211343\teval-rmse:0.324803\n",
      "[462]\ttrain-rmse:0.211272\teval-rmse:0.324807\n",
      "[463]\ttrain-rmse:0.211228\teval-rmse:0.324797\n",
      "[464]\ttrain-rmse:0.211139\teval-rmse:0.324788\n",
      "[465]\ttrain-rmse:0.211088\teval-rmse:0.324797\n",
      "[466]\ttrain-rmse:0.211022\teval-rmse:0.324783\n",
      "[467]\ttrain-rmse:0.210886\teval-rmse:0.324828\n",
      "[468]\ttrain-rmse:0.210744\teval-rmse:0.324825\n",
      "[469]\ttrain-rmse:0.210601\teval-rmse:0.324818\n",
      "[470]\ttrain-rmse:0.210473\teval-rmse:0.324792\n",
      "[471]\ttrain-rmse:0.210311\teval-rmse:0.324793\n",
      "[472]\ttrain-rmse:0.210285\teval-rmse:0.324793\n",
      "[473]\ttrain-rmse:0.210204\teval-rmse:0.324803\n",
      "[474]\ttrain-rmse:0.210142\teval-rmse:0.324819\n",
      "[475]\ttrain-rmse:0.210082\teval-rmse:0.324811\n",
      "[476]\ttrain-rmse:0.209948\teval-rmse:0.324843\n",
      "[477]\ttrain-rmse:0.209845\teval-rmse:0.324826\n",
      "[478]\ttrain-rmse:0.209733\teval-rmse:0.324805\n",
      "[479]\ttrain-rmse:0.209642\teval-rmse:0.324811\n",
      "[480]\ttrain-rmse:0.209616\teval-rmse:0.324802\n",
      "[481]\ttrain-rmse:0.209507\teval-rmse:0.324794\n",
      "[482]\ttrain-rmse:0.209352\teval-rmse:0.324782\n",
      "[483]\ttrain-rmse:0.209204\teval-rmse:0.324776\n",
      "[484]\ttrain-rmse:0.209038\teval-rmse:0.324795\n",
      "[485]\ttrain-rmse:0.208984\teval-rmse:0.324797\n",
      "[486]\ttrain-rmse:0.208819\teval-rmse:0.324775\n",
      "[487]\ttrain-rmse:0.208683\teval-rmse:0.324753\n",
      "[488]\ttrain-rmse:0.208511\teval-rmse:0.324740\n",
      "[489]\ttrain-rmse:0.208401\teval-rmse:0.324746\n",
      "[490]\ttrain-rmse:0.208322\teval-rmse:0.324751\n",
      "[491]\ttrain-rmse:0.208199\teval-rmse:0.324724\n",
      "[492]\ttrain-rmse:0.208133\teval-rmse:0.324720\n",
      "[493]\ttrain-rmse:0.207961\teval-rmse:0.324704\n",
      "[494]\ttrain-rmse:0.207839\teval-rmse:0.324693\n",
      "[495]\ttrain-rmse:0.207736\teval-rmse:0.324684\n",
      "[496]\ttrain-rmse:0.207643\teval-rmse:0.324681\n",
      "[497]\ttrain-rmse:0.207562\teval-rmse:0.324675\n",
      "[498]\ttrain-rmse:0.207499\teval-rmse:0.324666\n",
      "[499]\ttrain-rmse:0.207400\teval-rmse:0.324661\n",
      "[500]\ttrain-rmse:0.207285\teval-rmse:0.324671\n",
      "[501]\ttrain-rmse:0.207273\teval-rmse:0.324665\n",
      "[502]\ttrain-rmse:0.207232\teval-rmse:0.324678\n",
      "[503]\ttrain-rmse:0.207109\teval-rmse:0.324652\n",
      "[504]\ttrain-rmse:0.207011\teval-rmse:0.324663\n",
      "[505]\ttrain-rmse:0.206893\teval-rmse:0.324653\n",
      "[506]\ttrain-rmse:0.206695\teval-rmse:0.324635\n",
      "[507]\ttrain-rmse:0.206640\teval-rmse:0.324630\n",
      "[508]\ttrain-rmse:0.206488\teval-rmse:0.324604\n",
      "[509]\ttrain-rmse:0.206373\teval-rmse:0.324615\n",
      "[510]\ttrain-rmse:0.206280\teval-rmse:0.324602\n",
      "[511]\ttrain-rmse:0.206221\teval-rmse:0.324603\n",
      "[512]\ttrain-rmse:0.206092\teval-rmse:0.324625\n",
      "[513]\ttrain-rmse:0.206051\teval-rmse:0.324626\n",
      "[514]\ttrain-rmse:0.205899\teval-rmse:0.324620\n",
      "[515]\ttrain-rmse:0.205862\teval-rmse:0.324635\n",
      "[516]\ttrain-rmse:0.205757\teval-rmse:0.324638\n",
      "[517]\ttrain-rmse:0.205674\teval-rmse:0.324635\n",
      "[518]\ttrain-rmse:0.205594\teval-rmse:0.324642\n",
      "[519]\ttrain-rmse:0.205486\teval-rmse:0.324622\n",
      "[520]\ttrain-rmse:0.205328\teval-rmse:0.324592\n",
      "[521]\ttrain-rmse:0.205221\teval-rmse:0.324607\n",
      "[522]\ttrain-rmse:0.205082\teval-rmse:0.324620\n",
      "[523]\ttrain-rmse:0.205063\teval-rmse:0.324611\n",
      "[524]\ttrain-rmse:0.205043\teval-rmse:0.324604\n",
      "[525]\ttrain-rmse:0.204854\teval-rmse:0.324583\n",
      "[526]\ttrain-rmse:0.204730\teval-rmse:0.324581\n",
      "[527]\ttrain-rmse:0.204590\teval-rmse:0.324620\n",
      "[528]\ttrain-rmse:0.204516\teval-rmse:0.324609\n",
      "[529]\ttrain-rmse:0.204434\teval-rmse:0.324622\n",
      "[530]\ttrain-rmse:0.204328\teval-rmse:0.324634\n",
      "[531]\ttrain-rmse:0.204302\teval-rmse:0.324619\n",
      "[532]\ttrain-rmse:0.204196\teval-rmse:0.324617\n",
      "[533]\ttrain-rmse:0.204148\teval-rmse:0.324607\n",
      "[534]\ttrain-rmse:0.204098\teval-rmse:0.324614\n",
      "[535]\ttrain-rmse:0.204049\teval-rmse:0.324615\n",
      "[536]\ttrain-rmse:0.203965\teval-rmse:0.324602\n",
      "[537]\ttrain-rmse:0.203892\teval-rmse:0.324606\n",
      "[538]\ttrain-rmse:0.203775\teval-rmse:0.324591\n",
      "[539]\ttrain-rmse:0.203687\teval-rmse:0.324585\n",
      "[540]\ttrain-rmse:0.203606\teval-rmse:0.324582\n",
      "[541]\ttrain-rmse:0.203552\teval-rmse:0.324579\n",
      "[542]\ttrain-rmse:0.203479\teval-rmse:0.324586\n",
      "[543]\ttrain-rmse:0.203454\teval-rmse:0.324580\n",
      "[544]\ttrain-rmse:0.203316\teval-rmse:0.324565\n",
      "[545]\ttrain-rmse:0.203218\teval-rmse:0.324563\n",
      "[546]\ttrain-rmse:0.203121\teval-rmse:0.324564\n",
      "[547]\ttrain-rmse:0.203048\teval-rmse:0.324572\n",
      "[548]\ttrain-rmse:0.202949\teval-rmse:0.324573\n",
      "[549]\ttrain-rmse:0.202875\teval-rmse:0.324578\n",
      "[550]\ttrain-rmse:0.202768\teval-rmse:0.324613\n",
      "[551]\ttrain-rmse:0.202691\teval-rmse:0.324652\n",
      "[552]\ttrain-rmse:0.202564\teval-rmse:0.324678\n",
      "[553]\ttrain-rmse:0.202450\teval-rmse:0.324683\n",
      "[554]\ttrain-rmse:0.202386\teval-rmse:0.324691\n",
      "[555]\ttrain-rmse:0.202258\teval-rmse:0.324696\n",
      "[556]\ttrain-rmse:0.202240\teval-rmse:0.324694\n",
      "[557]\ttrain-rmse:0.202124\teval-rmse:0.324696\n",
      "[558]\ttrain-rmse:0.201994\teval-rmse:0.324698\n",
      "[559]\ttrain-rmse:0.201936\teval-rmse:0.324701\n",
      "[560]\ttrain-rmse:0.201848\teval-rmse:0.324699\n",
      "[561]\ttrain-rmse:0.201778\teval-rmse:0.324706\n",
      "[562]\ttrain-rmse:0.201672\teval-rmse:0.324717\n",
      "[563]\ttrain-rmse:0.201617\teval-rmse:0.324707\n",
      "[564]\ttrain-rmse:0.201478\teval-rmse:0.324744\n",
      "[565]\ttrain-rmse:0.201395\teval-rmse:0.324730\n",
      "[566]\ttrain-rmse:0.201353\teval-rmse:0.324715\n",
      "[567]\ttrain-rmse:0.201212\teval-rmse:0.324723\n",
      "[568]\ttrain-rmse:0.201110\teval-rmse:0.324725\n",
      "[569]\ttrain-rmse:0.201056\teval-rmse:0.324726\n",
      "[570]\ttrain-rmse:0.200962\teval-rmse:0.324714\n",
      "[571]\ttrain-rmse:0.200893\teval-rmse:0.324720\n",
      "[572]\ttrain-rmse:0.200790\teval-rmse:0.324714\n",
      "[573]\ttrain-rmse:0.200671\teval-rmse:0.324715\n",
      "[574]\ttrain-rmse:0.200489\teval-rmse:0.324734\n",
      "[575]\ttrain-rmse:0.200299\teval-rmse:0.324732\n",
      "[576]\ttrain-rmse:0.200167\teval-rmse:0.324760\n",
      "[577]\ttrain-rmse:0.200073\teval-rmse:0.324766\n",
      "[578]\ttrain-rmse:0.199992\teval-rmse:0.324750\n",
      "[579]\ttrain-rmse:0.199949\teval-rmse:0.324759\n",
      "[580]\ttrain-rmse:0.199821\teval-rmse:0.324753\n",
      "[581]\ttrain-rmse:0.199652\teval-rmse:0.324764\n",
      "[582]\ttrain-rmse:0.199513\teval-rmse:0.324746\n",
      "[583]\ttrain-rmse:0.199421\teval-rmse:0.324762\n",
      "[584]\ttrain-rmse:0.199364\teval-rmse:0.324765\n",
      "[585]\ttrain-rmse:0.199242\teval-rmse:0.324766\n",
      "[586]\ttrain-rmse:0.199150\teval-rmse:0.324751\n",
      "[587]\ttrain-rmse:0.199127\teval-rmse:0.324746\n",
      "[588]\ttrain-rmse:0.199090\teval-rmse:0.324728\n",
      "[589]\ttrain-rmse:0.198944\teval-rmse:0.324719\n",
      "[590]\ttrain-rmse:0.198870\teval-rmse:0.324726\n",
      "[591]\ttrain-rmse:0.198821\teval-rmse:0.324721\n",
      "[592]\ttrain-rmse:0.198758\teval-rmse:0.324724\n",
      "[593]\ttrain-rmse:0.198631\teval-rmse:0.324709\n",
      "[594]\ttrain-rmse:0.198495\teval-rmse:0.324709\n",
      "[595]\ttrain-rmse:0.198416\teval-rmse:0.324711\n",
      "[596]\ttrain-rmse:0.198316\teval-rmse:0.324707\n",
      "[597]\ttrain-rmse:0.198258\teval-rmse:0.324713\n",
      "[598]\ttrain-rmse:0.198216\teval-rmse:0.324733\n",
      "[599]\ttrain-rmse:0.198193\teval-rmse:0.324728\n",
      "[600]\ttrain-rmse:0.198160\teval-rmse:0.324741\n",
      "[601]\ttrain-rmse:0.198051\teval-rmse:0.324713\n",
      "[602]\ttrain-rmse:0.197973\teval-rmse:0.324704\n",
      "[603]\ttrain-rmse:0.197936\teval-rmse:0.324694\n",
      "[604]\ttrain-rmse:0.197826\teval-rmse:0.324702\n",
      "[605]\ttrain-rmse:0.197735\teval-rmse:0.324693\n",
      "[606]\ttrain-rmse:0.197623\teval-rmse:0.324660\n",
      "[607]\ttrain-rmse:0.197509\teval-rmse:0.324644\n",
      "[608]\ttrain-rmse:0.197415\teval-rmse:0.324664\n",
      "[609]\ttrain-rmse:0.197312\teval-rmse:0.324667\n",
      "[610]\ttrain-rmse:0.197269\teval-rmse:0.324663\n",
      "[611]\ttrain-rmse:0.197206\teval-rmse:0.324674\n",
      "[612]\ttrain-rmse:0.197075\teval-rmse:0.324664\n",
      "[613]\ttrain-rmse:0.196945\teval-rmse:0.324668\n",
      "[614]\ttrain-rmse:0.196869\teval-rmse:0.324658\n",
      "[615]\ttrain-rmse:0.196748\teval-rmse:0.324652\n",
      "[616]\ttrain-rmse:0.196637\teval-rmse:0.324659\n",
      "[617]\ttrain-rmse:0.196588\teval-rmse:0.324661\n",
      "[618]\ttrain-rmse:0.196462\teval-rmse:0.324648\n",
      "[619]\ttrain-rmse:0.196354\teval-rmse:0.324656\n",
      "[620]\ttrain-rmse:0.196296\teval-rmse:0.324645\n",
      "[621]\ttrain-rmse:0.196179\teval-rmse:0.324664\n",
      "[622]\ttrain-rmse:0.196035\teval-rmse:0.324617\n",
      "[623]\ttrain-rmse:0.195927\teval-rmse:0.324612\n",
      "[624]\ttrain-rmse:0.195885\teval-rmse:0.324608\n",
      "[625]\ttrain-rmse:0.195763\teval-rmse:0.324605\n",
      "[626]\ttrain-rmse:0.195660\teval-rmse:0.324589\n",
      "[627]\ttrain-rmse:0.195560\teval-rmse:0.324613\n",
      "[628]\ttrain-rmse:0.195490\teval-rmse:0.324592\n",
      "[629]\ttrain-rmse:0.195324\teval-rmse:0.324601\n",
      "[630]\ttrain-rmse:0.195202\teval-rmse:0.324625\n",
      "[631]\ttrain-rmse:0.195105\teval-rmse:0.324594\n",
      "[632]\ttrain-rmse:0.195072\teval-rmse:0.324594\n",
      "[633]\ttrain-rmse:0.194964\teval-rmse:0.324593\n",
      "[634]\ttrain-rmse:0.194913\teval-rmse:0.324596\n",
      "[635]\ttrain-rmse:0.194895\teval-rmse:0.324603\n",
      "[636]\ttrain-rmse:0.194791\teval-rmse:0.324603\n",
      "[637]\ttrain-rmse:0.194705\teval-rmse:0.324590\n",
      "[638]\ttrain-rmse:0.194598\teval-rmse:0.324598\n",
      "[639]\ttrain-rmse:0.194490\teval-rmse:0.324590\n",
      "[640]\ttrain-rmse:0.194414\teval-rmse:0.324606\n",
      "[641]\ttrain-rmse:0.194337\teval-rmse:0.324610\n",
      "[642]\ttrain-rmse:0.194295\teval-rmse:0.324612\n",
      "[643]\ttrain-rmse:0.194199\teval-rmse:0.324607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "RMSE: 0.988670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[644]\ttrain-rmse:0.194084\teval-rmse:0.324593\n",
      "[645]\ttrain-rmse:0.193966\teval-rmse:0.324593\n",
      "Stopping. Best iteration:\n",
      "[545]\ttrain-rmse:0.203218\teval-rmse:0.324563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = train_xgboost(train_valid, feat2, num_boost_round=5000, eta=0.02, max_depth=8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = xgboost_predict(gbm, sts_test[feat2].to_dataframe(), feat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "\n",
    "def output_to_file(team_name, run_name, target):\n",
    "    test_dir = '../sts2016-english-v1.1/'\n",
    "    filenames = [test_dir+i for i in os.listdir(test_dir) if i.endswith('ascii')]\n",
    "    for infile in filenames:\n",
    "        domain = infile.rpartition('.')[0].rpartition('.')[2]\n",
    "        outfile = 'STS2016.OUTPUT.'+team_name+'.'+run_name+'.'+domain+'.txt'\n",
    "        with io.open(infile, 'r') as fin, io.open(outfile, 'w') as fout:\n",
    "            domain_data = sts_test.filter_by(domain, column_name='Domain')\n",
    "            for line, row in zip(fin, domain_data):\n",
    "                #line = line.split('\\t')\n",
    "                #s1, s2 = line[0], line[1]\n",
    "                fout.write(unicode(row[target])+'\\n')\n",
    "\n",
    "sts_test.add_column(gl.SArray(m1.predict(sts_test)), name='pred_m1')\n",
    "sts_test.add_column(gl.SArray(m2.predict(sts_test)), name='pred_m2')                \n",
    "sts_test.add_column(gl.SArray(predictions), name='pred_xgboost')\n",
    "output_to_file('wolvesaar', 'DLS-replica', 'pred_m1')\n",
    "output_to_file('wolvesaar', 'lotsa-embeddings', 'pred_m2')\n",
    "output_to_file('wolvesaar', 'xgboost', 'pred_xgboost')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
